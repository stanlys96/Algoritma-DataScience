{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa88e5ea",
   "metadata": {},
   "source": [
    "**LearnPy: Python for Data Analytics**\n",
    "\n",
    "- Author : Team Algoritma\n",
    "- Developed by Algoritma's product division and instructors team\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646b4e88",
   "metadata": {
    "id": "35Nwbasyoqb0"
   },
   "source": [
    "# Learn Python - Introduction to Machine Learning 1: Classification & Regression\n",
    "\n",
    "Selamat datang di Learn Python - Introduction to Machine Learning 1. Notebook ini berisi latihan bagaimana cara membuat model untuk klasifikasi dan regresi yang dapat digunakan untuk melatih kemampuan Anda. Pada bagian ini Anda akan diperkenalkan dengan workflow dari Machine Learning mulai dari melakukan *exploratory data analysis* (EDA), melakukan pembersihan data (*preprocessing*), membuat model, dan melakukan evaluasi. Mari berlatih!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e066c86",
   "metadata": {},
   "source": [
    "##  Machine Learning Workflow: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f32d09d",
   "metadata": {},
   "source": [
    "### Case Study: Coronary Heart Disease"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb625445",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"assets/chd.jpg\" alt=\"Coronary Heart Disease\" width=\"350\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae50cd30",
   "metadata": {},
   "source": [
    "Penyakit jantung koroner adalah jenis penyakit jantung ketika arteri jantung tidak dapat mengalirkan cukup darah yang kaya oksigen ke jantung. Kondisi ini mempengaruhi arteri koroner yang lebih besar pada permukaan jantung. Masalah gangguan jantung ini dapat menimbulkan sejumlah keluhan. Mulai dari nyeri dada, sesak napas dan gejala serangan jantung. \n",
    "\n",
    "Beberapa faktor yang meningkatkan risiko seseorang terkena jantung koroner diantaranya yaitu:\n",
    "> - Tekanan darah tinggi\n",
    "> - Kolesterol dan trigliserida tinggi\n",
    "> - Diabetes\n",
    "> - Kegemukan\n",
    "> - Kebiasaan merokok\n",
    "> - Peradangan pada pembuluh darah\n",
    "> - Dan faktor lainnya"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab7be7c",
   "metadata": {},
   "source": [
    "Untuk dapat membuat model machine learning yang dapat memprediksi seseorang terkena jantung koroner atau tidak, kita membutuhkan sebuah program/algoritma. Salah satu library yang akan banyak digunakan untuk kebutuhan machine learning baik algoritma atau dataset di Python adalah `sklearn`. Dokumentasinya ada [di sini](https://scikit-learn.org/stable/). Namun sebelum itu, kita harus melakukan load dataset dan melakukan proses pembersihan data terlebih dahulu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9d5afd",
   "metadata": {},
   "source": [
    "### 1. Load Data: Coronary Heart Disease Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c9727b",
   "metadata": {},
   "source": [
    "Mari kita mulai dengan mengimpor library yang diperlukan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac62ff41",
   "metadata": {
    "executionInfo": {
     "elapsed": 571,
     "status": "ok",
     "timestamp": 1671516136031,
     "user": {
      "displayName": "Fiqey Indriati Eka Sari",
      "userId": "04659319313698685491"
     },
     "user_tz": -420
    },
    "id": "Xu_Uo9FEJbQP"
   },
   "outputs": [],
   "source": [
    "# library untuk manipulasi data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# library untuk menampilkan visualisasi\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# library untuk preprocessing -> scaling data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# library untuk preprocessing -> membagi dataset menjadi train dan test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# library untuk membuat model machine learning\n",
    "from sklearn import svm\n",
    "\n",
    "# library untuk evaluasi model\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ccf971",
   "metadata": {},
   "source": [
    "Mari kita baca dataset `data_input/CHDdata.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7699a397",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "patient = pd.read_csv(\"data_input/CHDdata.csv\")\n",
    "patient.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f707f5",
   "metadata": {},
   "source": [
    " ðŸ”Ž **Penjelasan Data**\n",
    "\n",
    "_variabel prediktor:_\n",
    "- `sbp` : _Systolic blood pressure_ atau tekanan darah sistolik (mmHg).\n",
    "- `tobacco`: Konsumsi tembakau per tahun (kg).\n",
    "- `ldl`: _Low density lipoprotein_ atau kadar kolesterol LDL dalam darah.\n",
    "- `adiposity`: Adipositas atau kelebihan timbunan lemak dalam tubuh.\n",
    "- `famhist`: _Family history_ atau riwayat keluarga jantung koroner (present = ada riwayat, absent = tidak ada riwayat).\n",
    "- `typea`: Skor kepribadian tipe A. Kepribadian tipe A memiliki tingkat stress yang lebih tinggi.\n",
    "- `obesity`: Skor _body mass index_ (BMI).\n",
    "- `alcohol`: Konsumsi alkohol.\n",
    "- `age`: Usia pasien (tahun).\n",
    "\n",
    "_variabel target:_\n",
    "\n",
    "- `chd`: _Coronary heart disease_ (0: sehat, 1: jantung koroner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eceba7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<a href=\"https://www.kaggle.com/datasets/billbasener/coronary-heart-disease\"><b>[Coronary Heart Disease Dataset]</b></a> adalah data yang mengandung informasi medis dari pasien. Tujuan dari projek ini adalah <b>membantu tenaga medis dengan memprediksi apakah seorang pasien terkena jantung koroner atau tidak </b> berdasarkan data medis dan gaya hidup pasien.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c553cd0b",
   "metadata": {},
   "source": [
    "### 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfc82b5",
   "metadata": {},
   "source": [
    "Tahapan-tahapan yang dapat dilakukan pada EDA antara lain:\n",
    "\n",
    "> - Melihat tipe data, missing value dan data duplikat\n",
    "> - Melihat deskripsi statistik data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3564921f",
   "metadata": {},
   "source": [
    "#### 2.1 Tipe Data, Missing Value dan Duplikat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14fe371",
   "metadata": {},
   "source": [
    "##### `1ï¸âƒ£` Tipe Data\n",
    "\n",
    "Tipe data yang tepat sangat penting sebelum membangun model machine learning. **Kesalahan tipe data dapat menyebabkan misinterpretasi oleh model dan menurunkan performanya.**\n",
    "\n",
    "Contohnya, jika kolom numerik masih dalam bentuk string, model tidak dapat melakukan operasi matematika dan menghasilkan error.\n",
    "\n",
    "Mari kita melihat dan menyesuaikan tipe data dari dataset kita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0f1439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# melihat tipe data tiap kolom\n",
    "patient.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002a607c",
   "metadata": {},
   "source": [
    "> Terlihat bahwa prediktor `famhist` memiliki tipe data `object`. Kita perlu mengubahnya menjadi data `category` menggunakan fungsi `.astype()` yang sudah disediakan oleh python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab81cf7a",
   "metadata": {},
   "source": [
    "#### Quiz 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c0434a",
   "metadata": {},
   "source": [
    "___\n",
    "1. Ubah kolom bertipe object menjadi category.\n",
    "\n",
    "> âœ¨ Hint: Perhatikan gambar berikut!\n",
    "\n",
    "<!-- \n",
    "Reference answer :\n",
    "\n",
    "```python\n",
    "# list kolom yang akan dijadikan kategori\n",
    "cat_features = ['famhist']\n",
    "\n",
    "# mengubah tipe data\n",
    "patient[cat_features] = patient[cat_features].astype('category')\n",
    "\n",
    "# menampilkan tipe data\n",
    "patient.dtypes\n",
    "```\n",
    "-->\n",
    "\n",
    "\n",
    "![](assets/svm_data_type.png) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca656a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d5e56f",
   "metadata": {},
   "source": [
    "##### `2ï¸âƒ£` Missing Value\n",
    "\n",
    "Missing value dapat terjadi karena berbagai alasan. Hal ini dapat memengaruhi performa model atau bahkan menggagalkan proses pemodelan. Oleh karena itu, penting untuk menangani missing value sebelum membangun model.\n",
    "\n",
    " ðŸ”Ž **Menangani Missing Value**\n",
    "\n",
    "Untuk treatment missing values sebenarnya ada beberapa cara umum yang bisa digunakan. Antara lain:\n",
    "\n",
    "> - **Imputasi:** Mengisi nilai yang hilang dengan nilai lain: Menggunakan metode `.fillna()`\n",
    "> - **Drop:** Menghapus observasi yang memiliki nilai missing: Menggunakan metode `.dropna()`. Namun jika nilai missing > 5%, maka tidak disarankan menggunakan metode ini."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f2b271",
   "metadata": {},
   "source": [
    "Metode imputasi bisa berbeda tergantung jenis tipe datanya. Berikut detail metode imputasi yang bisa digunakan.\n",
    "\n",
    "**Untuk kolom categorical:**\n",
    "\n",
    "> - Isi menggunakan nilai lainnya seperti `other` atau `missing`\n",
    "> - Isi menggunakan nilai terbanyak yg muncul (`mode`)\n",
    "\n",
    "**Untuk kolom numerical:**\n",
    "\n",
    "> - Isi menggunakan nilai tengah seperti `mean` atau `median`\n",
    "> - Isi dengan nilai 0\n",
    "\n",
    "**Untuk kolom datetime:**\n",
    "\n",
    "> - Menggunakan metode `bfill` : melakukan imputasi dari bawah ke atas\n",
    "> - Menggunakan metode `ffill` : melakukan imputasi dari atas ke bawah"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f01ab7",
   "metadata": {},
   "source": [
    "___\n",
    "2. Ada berapa nilai missing pada kolom `famhist` ?\n",
    "\n",
    "> âœ¨ Hint: Gunakan tambahan fungsi **.sum()** untuk melihat jumlah angkanya.\n",
    "\n",
    "- [ ] Tidak ada\n",
    "- [ ] 2\n",
    "- [ ] 10\n",
    "\n",
    "<!-- \n",
    "Reference answer :\n",
    "\n",
    "```python\n",
    "# menampilkan missing value tiap kolom\n",
    "patient.isna().sum()\n",
    "```\n",
    "\n",
    "Berdasarkan fungsi di atas, dataset patient tidak memiliki nilai missing. Sehingga pada kolom famhist juga TIDAK ADA missing value.\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a1e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f18d35",
   "metadata": {},
   "source": [
    "##### `3ï¸âƒ£` Duplicate Value\n",
    "\n",
    "Nilai duplikat adalah baris yang memiliki kesamaan nilai dengan 1 atau lebih baris yang lain.\n",
    "\n",
    "**Nilai duplikat dalam dataset dapat menyebabkan hasil pemodelan yang bias dan tidak akurat karena mementingkan nilai-nilai yang duplikat.**\n",
    "\n",
    "Oleh karena itu, penting untuk mengidentifikasi nilai duplikat sebelum membangun model machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b593a1",
   "metadata": {},
   "source": [
    "___\n",
    "3. Tampilkan berapa jumlah baris yang duplikat pada dataset.\n",
    "\n",
    "> âœ¨ Hint: Gunakan tambahan fungsi **.sum()** untuk melihat jumlah angkanya.\n",
    "\n",
    "- [ ] Tidak ada\n",
    "- [ ] 2\n",
    "- [ ] 10\n",
    "\n",
    "<!-- \n",
    "Reference answer :\n",
    "\n",
    "```python\n",
    "# menampilkan data duplikat\n",
    "patient.duplicated().sum()\n",
    "```\n",
    "\n",
    "Berdasarkan fungsi di atas, dataset patient tidak memiliki nilai duplikat.\n",
    "\n",
    "-->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6685b70a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814d7025",
   "metadata": {},
   "source": [
    "#### 2.2 Melihat Deskripsi Statistik Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c45e4a2",
   "metadata": {},
   "source": [
    "___\n",
    "4. Menggunakan dataframe `patient`, berapa nilai tengah tekanan darah sistolik pasien? \n",
    "\n",
    "> Hint : Anda mungkin membutuhkan method `describe()` untuk melihat statistik data.\n",
    "\n",
    "- [ ] 124 mmHg\n",
    "- [ ] 134 mmHg\n",
    "- [ ] 138 mmHg\n",
    "\n",
    "<!-- \n",
    "\n",
    "Reference answer :\n",
    "\n",
    "```python\n",
    "# melihat statistik dataset\n",
    "patient.describe()\n",
    "```\n",
    "\n",
    "Jadi nilai tengah (median) dari tekanan darah sistolik pasien sebesar 134 mmHg => hipertensi tingkat 1\n",
    "\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4aabe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46956c6f",
   "metadata": {},
   "source": [
    "___\n",
    "5. Menggunakan data pada nomor 1, berapa skor rata-rata _Body Mass Index_ pasien?\n",
    "\n",
    "- [ ] 25 Kg/MÂ²\n",
    "- [ ] 26 Kg/MÂ²\n",
    "- [ ] 28 Kg/MÂ²\n",
    "\n",
    "<!-- \n",
    "\n",
    "Berdasarkan data statistik pada nomor 1, rata-rata pasien memiliki skor BMI (obesity) sebesar 26 Kg/MÂ²a\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81c092a",
   "metadata": {},
   "source": [
    "___\n",
    "6. Menggunakan data pada nomor 1, berapa jumlah pasien yang memiliki riwayat keturunan penyakit jantung?\n",
    "\n",
    "> Hint : Anda mungkin membutuhkan method `include()` untuk melihat statistik data pada data kategorik.\n",
    "\n",
    "- [ ] 192 pasien\n",
    "- [ ] 270 pasien\n",
    "- [ ] 462 pasien\n",
    "\n",
    "<!-- \n",
    "\n",
    "Reference answer :\n",
    "\n",
    "```python\n",
    "# menampilkan data statistik untuk tipe data kategorikal\n",
    "patient.describe(include='category')\n",
    "```\n",
    "\n",
    "Dari 462 pasien, 270 pasien tidak memiliki riwayat (absent). Jadi pasien yang memiliki riwayat keturunan penyakit jantung sebesar 462 - 270 = 192 pasien.\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd90dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cefb77",
   "metadata": {},
   "source": [
    "### 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dff225",
   "metadata": {},
   "source": [
    "Data preprocessing merupakan proses untuk membersihkan data dari data mentah menjadi data yang baik dan lengkap untuk proses modeling. Data yang bersih dan lengkap akan menghasilkan model machine learning yang efektif dan efisien serta memiliki performa yang lebih baik.\n",
    "\n",
    "Proses ini bertujuan untuk mengurangi waktu komputasi dan resource yang dibutuhkan saat proses pembuatan model dan meningkatkan performa model machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21020c4a",
   "metadata": {},
   "source": [
    "Tahapan-tahapan yang dapat dilakukan pada data preprocessing antara lain:\n",
    "\n",
    "> - Menangani data outliers\n",
    "> - Menangani data kategorikal\n",
    "> - Membagi dataset menjadi data train dan test\n",
    "> - Melakukan scaling data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c12ed2",
   "metadata": {},
   "source": [
    "#### 3.1 Handling Numerical Data: Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a80ff92",
   "metadata": {},
   "source": [
    "Outlier adalah observasi dengan nilai yang jauh berbeda dari mayoritas data. Hal ini dapat disebabkan oleh kesalahan input, anomali, atau kesalahan perhitungan. Menangani outlier penting dalam pemodelan machine learning karena dapat memengaruhi performa model.\n",
    "\n",
    " ðŸ”Ž **Menangani Outliers**\n",
    " \n",
    "Ada beberapa cara untuk menangani outliers:\n",
    "1. **Remove outlier**: Menghilangkan dan menghapus keseluruhan outlier. Metode ini tidak disarankan jika jumlah outliers > 5% dari total data.\n",
    "2. **Imputasi**: Mengganti nilai outliers dengan nilai yang diperbolehkan (sesuai kebutuhan).\n",
    "3. ***Scaling***: Teknik untuk mentrasformasi sehingga nilai-nilai outlier ini tidak akan berpengaruh besar terhadap hasil analisis. Teknik scaling bermacam-macam, seperti standarisasi, normalisasi, min-max scaler dan lain sebagainya.\n",
    "\n",
    "\n",
    "Mari kita identifikasi nilai outlier pada data kita dengan menggunakan boxplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505352f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list kolom numerik\n",
    "num_features = ['sbp', 'tobacco', 'ldl', 'adiposity', 'typea', 'obesity', 'alcohol', 'age']\n",
    "\n",
    "# visualisasi boxplot\n",
    "patient.boxplot(column=num_features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669a18c6",
   "metadata": {},
   "source": [
    "> ðŸ’¡ **INSIGHT:** Dari visualisasi boxplot di atas terlihat adanya outlier pada beberapa kolom seperti `sbp`, `tobacco`, `ldl`, `typea`, `obesity`, dan `alcohol`. Untuk mengatasi ini, kita coba menggunakan teknik ketiga yaitu scaling. Hal ini dikarenakan cukup banyak outlier dan menghindari kehilangan banyak data jika dihapus. Sehingga akan digunakan proses scaling untuk mengurangi pengaruh dari outlier. Proses scaling akan dilakukan setelah train-test splitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e217e19",
   "metadata": {},
   "source": [
    "#### 3.2 Handling Categorical Data\n",
    "\n",
    "Model machine learning hanya bisa belajar dari data berupa angka. Jadi jika ada prediktor yang memilili tipe data bukan angka, perlu diubah terlebih dahulu ke bentuk angka. \n",
    "\n",
    "Prediktor `famhist` merupakan data kategorik dan termasuk tipe nominal karena tidak memiliki hubungan bertingkat antar kategorinya. Untuk itu akan digunakan metode *dummy variable encoding* membuat kolom baru bertipe biner untuk masing-masing kategorinya."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59a88a3",
   "metadata": {},
   "source": [
    "Untuk melakukan **Dummy Variable Encoding** kita menggunakan `pd.get_dummies()` dengan memasukkan kolom yang ingin kita ubah. Adapun parameter antara lain:\n",
    "\n",
    "- `data`: data yang ingin diubah menjadi numerikal\n",
    "\n",
    "- `columns`: list nama kolom yang akan dilakukan dummy variable encoding\n",
    "\n",
    "- `drop_first`: Drop salah satu kolom (kolom pertama). Default False (Tidak ada kolom di drop). True agar kolom hasil dummies tidak rendundan.\n",
    "\n",
    "- `dtype` : Mengubah tipe data hasil encoding menjadi suatu tipe data\n",
    "\n",
    "Dokumentasi `pd.get_dummies()` dapat diakses [di sini](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html)\n",
    "\n",
    "Mari kita coba menerapkan **Dummy Variable Encoding** untuk kolom yang telah kita disepakati"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a39523",
   "metadata": {},
   "source": [
    "#### Quiz 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0a060b",
   "metadata": {},
   "source": [
    "1. Menggunakan fungsi **.get_dummies()**, ubah kolom kategorical `famhist` menjadi angka numerik bertipe `int64`. Atur parameter **drop_first** agar bernilai True.\n",
    "\n",
    "> âœ¨ Hint: Perhatikan gambar di bawah ini.\n",
    "\n",
    "<!-- \n",
    "Reference answer :\n",
    "\n",
    "```python\n",
    "# list prediktor yang memiliki tipe nominal\n",
    "nominal_features = ['famhist']\n",
    "\n",
    "# implementasi pd.get_dummies\n",
    "patient = pd.get_dummies(patient, \n",
    "                         columns = nominal_features, \n",
    "                         drop_first = True, \n",
    "                         dtype = 'int64')\n",
    "patient.head()\n",
    "```\n",
    "-->\n",
    "\n",
    "![](assets/svm_categorical_data.png) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57eb3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6731defd",
   "metadata": {},
   "source": [
    "#### 3.3 Train-Test Splitting (*Cross Validation*)\n",
    "\n",
    "*Cross Validation* digunakan untuk mengetahui kemampuan model memprediksi data baru."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4aedfb",
   "metadata": {},
   "source": [
    "Untuk memahami performa model, membagi dataset menjadi training data dan testing data adalah strategi yang baik dengan menggunakan fungsi `train_test_split()`\n",
    "\n",
    "Pisahkan dataset dengan menggunakan fungsi `train_test_split()`. Anda harus melewati 3 parameter `features`, `target`, dan `test_size`. Selain itu, Anda dapat menggunakan `random_state` untuk memilih record secara acak."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2015ae78",
   "metadata": {},
   "source": [
    "Kita dapat menggunakan `train_test_split` dengan beberapa parameter sebagai berikut.\n",
    "- `*arrays`: dataframe yang kita gunakan (dipisah , untuk yang prediktor dan target variable)\n",
    "- `test_size`: jumlah persentase dari data yang akan digunakan sebagai data test\n",
    "- `train_size`: jumlah persentase dari data yang akan digunakan sebagai data test (akan otomatis terisi jika `test_size` diberi nilai)\n",
    "- `random_state`: nilai random number generator (RNG). Jika kita memasukkan suatu nilai integer untuk parameter ini maka akan menghasilkan hasil yang sama untuk nilai yang sama. Jika kita mengubah nilainya, maka hasilnya akan berbeda."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2d7765",
   "metadata": {},
   "source": [
    "> **ðŸ’¡ NOTES**: Biasanya data dibagi menjadi 80:20 atau 70:30 (train size:test size). Porsi yang besar selalu digunakan untuk training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc5410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# memilih kolom target\n",
    "target = 'chd'\n",
    "\n",
    "# menyimpan data kolom target ke dalam variabel y\n",
    "y = patient[target]\n",
    "\n",
    "# menghapus kolom target sehingga tersisa kolom prediktor dan dimasukkan ke variabel X\n",
    "X = patient.drop(columns=[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1f0447",
   "metadata": {},
   "source": [
    "___\n",
    "2. Menggunakan fungsi **train_test_split()**, bagi dataset menjadi data train dan data test dengan proporsi 70% data train dan 30% data test. Atur parameter `random_state` menjadi 100.\n",
    "\n",
    "<!-- \n",
    "Reference answer :\n",
    "\n",
    "```python\n",
    "# split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.30, # 70% training and 30% test\n",
    "                                                    random_state = 100)\n",
    "```\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d3f636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0160fd3",
   "metadata": {},
   "source": [
    "___\n",
    "3. Berdasarkan hasil `train_test_split`, berapa baris data yang digunakan untuk melatih model?\n",
    "\n",
    "- [ ] 70 data\n",
    "- [ ] 139 data\n",
    "- [ ] 323 data\n",
    "\n",
    "<!-- \n",
    "\n",
    "Reference answer :\n",
    "\n",
    "```python\n",
    "# cek dimensi data train\n",
    "X_train.shape\n",
    "```\n",
    "\n",
    "Dari 462 data dibagi menadi 70% data train (323 data) dan 30% data test (139 data).\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0106c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5a909f",
   "metadata": {},
   "source": [
    "___\n",
    "4. Berdasarkan hasil `train_test_split`, berapa baris data yang digunakan untuk menguji model?\n",
    "\n",
    "- [ ] 30 data\n",
    "- [ ] 139 data\n",
    "- [ ] 323 data\n",
    "\n",
    "<!-- \n",
    "\n",
    "Reference answer :\n",
    "\n",
    "```python\n",
    "# cek dimensi data test\n",
    "X_test.shape\n",
    "```\n",
    "\n",
    "Dari 462 data dibagi menadi 70% data train (323 data) dan 30% data test (139 data).\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e40af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6d4d21",
   "metadata": {},
   "source": [
    "#### 3.4 Scaling (*Z Score Nomalization*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd64ab10",
   "metadata": {},
   "source": [
    "Proses scaling dilakukan untuk menyeragamkan skala data antar prediktor. Hal ini penting dilakukan karena jika skala data antar prediktor tidak seragam, maka model machine learning akan bias (lebih memperhatikan) prediktor yang memiliki skala yang lebih besar. Hal ini akan membuat prediktor lain yang memiliki skala lebih kecil seakan-akan tidak memiliki pengaruh terhadap model dan akan membuat performa model tidak maksimal.\n",
    "\n",
    "Metode scaling sangat banyak sekali seperti standarisasi dan normalisasi. Untuk kasus ini kita akan menggunakan metode standarisasi Z score menggunakan fungsi `StandardScaler` dari library `sklearn` yang membuat data kita memiliki nilai `mean = 0` dan `standar deviasi = 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bbc814-233d-4d80-988c-0aaf3de2e492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat object dari class StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# proses fit scaling\n",
    "scaler.fit(X_train[num_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030eb293",
   "metadata": {},
   "source": [
    "___\n",
    "5. Setelah proses fit scaling data train pada kolom numerik yang terkumpul pada list `num_features`, lakukan proses transformasi pada kolom numerik yang sama untuk **data train** dan **data test** menggunakan fungsi **scaler.transform()**.\n",
    "\n",
    "<!-- \n",
    "Reference answer :\n",
    "\n",
    "```python\n",
    "# proses transform scaling\n",
    "X_train[num_features] = scaler.transform(X_train[num_features])\n",
    "X_test[num_features] = scaler.transform(X_test[num_features])\n",
    "```\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d992accb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b9ffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# melihat data setelah proses scaling\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7710ee2e",
   "metadata": {},
   "source": [
    "> **ðŸ’¡ NOTES**: Proses fit scaling hanya dilakukan pada data train untuk mencegah kebocoran (leak) pada data test. Hal ini dilakukan agar informasi pada data test benar-benar tidak bocor/tidak diketahui saat pembuatan model sehingga hasil evaluasi model lebih dapat dipertanggung jawabkan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb184b3f",
   "metadata": {},
   "source": [
    "### 4. Model Building: Support Vector Classifier (SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6e198a",
   "metadata": {},
   "source": [
    "Untuk mesin dapat belajar sesuai dengan kebutuhan kita, kita memerlukan algoritma yang disebut model. Terdapat banyak jenis model **machine learning** dan salah satu contohnya adalah Support Vector Machine.\n",
    "\n",
    "SVM dapat memecahkan masalah klasifikasi menggunakan `Support Vector Classifier (SVC)` dan regresi menggunakan `Support Vector Regressor (SVR)` dan dapat diperluas untuk memodelkan non-linearitas dalam data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477837e1",
   "metadata": {},
   "source": [
    "#### 4.1 SVC Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1d229f",
   "metadata": {},
   "source": [
    "ðŸ”»Setelah semua proses persiapan data selesai, kini adalah saatnya untuk 'mesin' belajar dan diuji oleh data kita.\n",
    "\n",
    "Langkah-langkah membangun model SVM. \n",
    "> 1. Import library SVC dari SVM.\n",
    "> 2. Buat variabel `model_svc` untuk menyimpan hasil model `SVC()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460807e5",
   "metadata": {},
   "source": [
    "1. Setelah proses preprocessing selesai, saatnya membuat model machine learning menggunakan algoritma SVM. Silakan panggil fungsi **SVC()** dari library **svm**, lalu masukkan ke variabel `model_svc`. Kemudian lakukan proses training menggunakan fungsi **.fit()**.\n",
    "\n",
    "> âœ¨ Hint: Masukkan data prediktor dan target di dalam fungsi **.fit()**.\n",
    "\n",
    "<!-- \n",
    "Reference answer :\n",
    "\n",
    "```python\n",
    "# membuat object SVC dari class svm\n",
    "model_svc = svm.SVC()\n",
    "\n",
    "# proses training\n",
    "model_svc.fit(X_train, y_train)\n",
    "```\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb5cb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea15b0ca",
   "metadata": {},
   "source": [
    "#### 4.2 Model Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1f113c",
   "metadata": {},
   "source": [
    "Setelah model dilatih, model siap digunakan untuk memprediksi data baru. Model akan memprediksi data test yang telah kita siapkan sebelumnya."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d790a1c1",
   "metadata": {},
   "source": [
    "___\n",
    "2. Menggunakan model yang telah dilatih, silakan gunakan model tersebut untuk memprediksi **data train** lalu masukkan hasilnya ke dalam variabel `y_pred_train`.\n",
    "\n",
    "> âœ¨ Hint: Gunakan prediktor dari data train.\n",
    "\n",
    "<!-- \n",
    "Reference answer :\n",
    "\n",
    "```python\n",
    "# prediksi data train\n",
    "y_pred_train = model_svc.predict(X_train)\n",
    "```\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91ce648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489e8677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# menampilkan 10 data hasil prediksi\n",
    "y_pred_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657e5a28",
   "metadata": {},
   "source": [
    "___\n",
    "3. Menggunakan model yang telah dilatih, silakan gunakan model tersebut untuk memprediksi **data test** lalu masukkan hasilnya ke dalam variabel `y_pred_test`.\n",
    "\n",
    "> âœ¨ Hint: Gunakan prediktor dari data test.\n",
    "\n",
    "<!-- \n",
    "Reference answer :\n",
    "\n",
    "```python\n",
    "# prediksi data test\n",
    "y_pred = model_svc.predict(X_test)\n",
    "```\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6671d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733b1ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# menampilkan 10 data hasil prediksi\n",
    "y_pred_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e72f0b9",
   "metadata": {},
   "source": [
    "**ðŸ’¡NOTES**: Walaupun kita sudah berhasil memprediksi, kita tetap perlu memastikan bahwa hasil prediksinya banyak yang benar / sudah sesuai dengan melakukan model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8dba0f",
   "metadata": {},
   "source": [
    "### 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb1bb8d",
   "metadata": {},
   "source": [
    "Setelah kita melakukan prediksi akan dilakukan evaluasi model dengan membandingkan nilai aktual dan hasil prediksi. Perbedaan antara nilai prediksi dengan nilai aktual disebut sebagai *error*, semakin kecil *error* maka semakin bagus model kita, karena nilai prediksi semakin mendekati nilai aslinya.\n",
    "\n",
    "Salah satu cara yang sering digunakan dalam menghitung error pada kasus klasifikasi adalah nilai akurasi. Berikut adalah formula menghitung nilai akurasi:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fece92",
   "metadata": {},
   "source": [
    "$$Accuracy = {\\text{Jumlah prediksi benar} \\over \\text{Total prediksi}}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a099f0",
   "metadata": {},
   "source": [
    "> Misal, saya punya 100 data, kemudian model berhasil memprediksi dengan benar 90 data, maka akurasinya adalah\n",
    "> 90/100 = 90%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ce63f2",
   "metadata": {},
   "source": [
    "ðŸ”» Fungsi `metrics.accuracy_score()` dari library `sklearn` berfungsi untuk menghitung akurasi berdasarkan data yang telah diprediksi oleh model. Parameter yang dimasukkan adalah:\n",
    "* `y_true`: target yang sebenarnya (ground truth) $\\rightarrow$ diambil dari `y_test`\n",
    "* `y_pred`: target hasil prediksi model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553446b6",
   "metadata": {},
   "source": [
    "Dokumentasi metrik evaluasi `accuracy` dan metrik lainnya dapat diakses [di sini](https://scikit-learn.org/stable/api/sklearn.metrics.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bcdea9",
   "metadata": {},
   "source": [
    "> Untuk mengetahui apakah model yang Anda buat underfit, good fit, atau overfit, mari bandingkan peforma model ketika memprediksi data train dan data test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a31afff",
   "metadata": {},
   "source": [
    "Evaluasi model menggunakan data train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997e09fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluasi model\n",
    "accuracy_train = metrics.accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "# tampilkan hasil evaluasi\n",
    "print(f\"Accuracy Train : {accuracy_train:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e23bb6",
   "metadata": {},
   "source": [
    "Evaluasi model menggunakan data test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3448259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluasi model\n",
    "accuracy_test = metrics.accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "# tampilkan hasil evaluasi\n",
    "print(f\"Accuracy Test : {accuracy_test:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c157a4d9",
   "metadata": {},
   "source": [
    "Membandingkan evaluasi model pada data train dan data test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f836d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# menampilkan perbandingan evaluasi model pada data train dan data test\n",
    "pd.DataFrame(data = {\"Accuracy\": [accuracy_train, accuracy_test]},\n",
    "             index = [\"Data Train\", 'Data Test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445a1f5b",
   "metadata": {},
   "source": [
    "> ðŸ’¡ **INSIGHT:** Dari hasil evaluasi, dapat dikatakan bahwa model kita belum memiliki performa yang baik karena mengalami overfitting. Hal ini ditandai dengan nilai akurasi pada data train dan test berbeda jauh. Untuk memperbaiki performa, perlu kita lakukan proses tuning hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e154573d",
   "metadata": {},
   "source": [
    "### 6. Model Improvement: Tuning Hyperparameter SVC (Opsional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82185049",
   "metadata": {},
   "source": [
    "Model tuning berguna untuk memperbaiki model kita dengan cara merubah nilai pada hyperparameter. Namun proses tuning tidak selalu menghasilkan model yang lebih baik sehingga kita perlu lakukan *trial and error* untuk mencari hyperparameter yang mampu meningkatkan performa model.\n",
    "\n",
    "Adapun *hyperparameter* yang sering digunakan dalam model SVC antara lain:\n",
    "- `C (regularization) [default = 1, range = 0.0 - inf]`: Regularisasi mengontrol margin dan jumlah kesalahan klasifikasi, semakin besar nilai C maka semakin kecil jumlah kesalahan, semakin kecil nilai C, semakin besar nilai kesalahan yang ditoleransi.\n",
    "- `kernel [default = 'rbf', option = ['rbf', 'poly', 'linear', 'sigmoid']`: Mempengaruhi bagaimana pemisah (*hyperplane*) terbentuk, untuk data yang dapat dipisahkan secara garis linear (garis lurus) dapat menggunakan 'linear'. Untuk data-data non-linear dapat menggunakan kernel `rbf`.\n",
    "*Note: Kebanyakan data berbentuk non-linear, sehingga sebaiknya selalu memilih kernel `rbf`*\n",
    "- `gamma [default = 'scale', option = ['scale', 'auto', positive float number]`: Semakin besar nilai gamma, garis pemisah semakin mengikuti bentuk data (semakin kompleks), semakin kecil, maka semakin garis pemisah lebih general (lebih sederhana).\n",
    "\n",
    "Untuk hyperparameter dan penjelasan lebih detail dapat dilihat pada [dokumentasi SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2efa27",
   "metadata": {},
   "source": [
    "Mari kita coba untuk tuning model Klasifikasi kita dengan nama `model_svc_tuning`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70795a5d",
   "metadata": {},
   "source": [
    "Buatlah model baru bernama `model_svc_tuning` yang memiliki parameter C=100, kernel=rbf, dan gamma=0.001. Lalu lakukan proses **.fit()** pada model tersebut menggunakan data train.\n",
    "\n",
    "> âœ¨ Hint: Gunakan prediktor dari data train.\n",
    "\n",
    "<!-- \n",
    "Reference answer :\n",
    "\n",
    "```python\n",
    "# membuat model svc tuning\n",
    "model_svc_tuning = svm.SVC(C = 100, kernel = 'rbf', gamma = 0.001)\n",
    "\n",
    "# melakukan pelatihan ulang\n",
    "model_svc_tuning.fit(X_train, y_train)\n",
    "```\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b55a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd04408a",
   "metadata": {},
   "source": [
    "Mari kita lihat performa model hasil tuning untuk memprediksi data train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediksi data train menggunakan model hasil tuning\n",
    "y_pred_train_tuning = model_svc_tuning.predict(X_train)\n",
    "\n",
    "# evaluasi model\n",
    "accuracy_train_tuning = metrics.accuracy_score(y_train, y_pred_train_tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579988ee",
   "metadata": {},
   "source": [
    "Mari kita lihat performa model hasil tuning untuk memprediksi data test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9ece5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediksi data test menggunakan model hasil tuning\n",
    "y_pred_test_tuning = model_svc_tuning.predict(X_test)\n",
    "\n",
    "# evaluasi model\n",
    "accuracy_test_tuning = metrics.accuracy_score(y_test, y_pred_test_tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e2acd7",
   "metadata": {},
   "source": [
    "Mari kita lihat perbandingan performa model data data train dan test sebelum dan sesudah tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8069eaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan perbandingan evaluasi model hasil tuning pada data train dan data test\n",
    "pd.DataFrame(data = {\"Accuracy Train\": [accuracy_train, accuracy_test],\n",
    "                     \"Accuracy Test\": [accuracy_train_tuning, accuracy_test_tuning]},\n",
    "             index = [\"Base Model\", 'Tuning Model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ea6196",
   "metadata": {},
   "source": [
    "**âœ¨ INSIGHT âœ¨**\n",
    "> Setelah dilakukan proses tuning, skor akurasi pada data test naik menjadi 71%. Hal ini menandakan bahwa model hasil tuning sudah bisa dikatakan model yang lebih baik. Meskipun model nya mengalami **Overfitting** karena nilai akurasi data train dan test tidak sama, tetapi hal ini masih bisa ditoleransi karena perbedaannya < 10%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ff2488",
   "metadata": {},
   "source": [
    "### **Notes**\n",
    "\n",
    "> **Reference anwer dapat Anda lihat pada setiap markdown soal**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6164e8e",
   "metadata": {},
   "source": [
    "##  Machine Learning Workflow: Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdeb6d8",
   "metadata": {},
   "source": [
    "### Case Study: Medical Insurance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e453ce12",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"assets/insurance.png\" alt=\"Medical Insurance\" width=\"400\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda3e0c5",
   "metadata": {},
   "source": [
    "Asuransi medis atau sering disebut juga asuransi kesehatan adalah jenis asuransi yang memberikan perlindungan finansial terhadap biaya yang terkait dengan perawatan kesehatan. Sama seperti jenis asuransi lainnya, asuransi medis juga membutuhkan pembayaran untuk setiap waktu tertentu. Besarnya biaya yang ditagih oleh pihak asuransi tergantung pada beberapa faktor seperti kondisi medis, jumlah anak, wilayah tempat tinggal, dan lainnya.\n",
    "\n",
    "Pada studi kasus kali ini, akan diberikan dataset biaya tagihan pembayaran asuransi medis di wilayah Amerika Serikat. Tugas kita adalah memprediksi berapa tagihan yang musti dibayarkan berdasarkan beberapa faktor yang ada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6938a321",
   "metadata": {},
   "source": [
    "### 1. Load Data: Medical Insurance Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e385be4b",
   "metadata": {},
   "source": [
    "Mari kita mulai dengan mengimpor library yang diperlukan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d3c2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library untuk manipulasi data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# library untuk menampilkan visualisasi\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# library untuk preprocessing -> scaling data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# library untuk preprocessing -> membagi dataset menjadi train dan test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# library untuk membuat model machine learning\n",
    "from sklearn import svm\n",
    "\n",
    "# library untuk evaluasi model\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fc8f44",
   "metadata": {},
   "source": [
    "Mari kita baca dataset `data_input/insurance.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fd2640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "insurance = pd.read_csv(\"data_input/insurance.csv\")\n",
    "insurance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4aeafe",
   "metadata": {},
   "source": [
    " ðŸ”Ž **Penjelasan Data**\n",
    "\n",
    "_variabel prediktor:_\n",
    "- `age` $\\rightarrow$ usia peserta asuransi (tahun).\n",
    "- `sex` $\\rightarrow$ jenis kelamin (male/female).\n",
    "- `bmi` $\\rightarrow$ _Body Mass Index_ atau masa index tubuh (kg/m2).\n",
    "- `children` $\\rightarrow$ jumlah anak yang ditanggung asuransi.\n",
    "- `smoker` $\\rightarrow$ apakah peserta asuransi merokok? (yes/no).\n",
    "- `region` $\\rightarrow$ wilayah tempat peserta asuransi tinggal (northeast, southeast, southwest, dan northwest)\n",
    "\n",
    "_variabel target:_\n",
    "\n",
    "- `charges` $\\rightarrow$ biaya tagihan asuransi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448ea1e2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<a href=\"https://www.kaggle.com/datasets/mirichoi0218/insurance/data\"><b>[Medical Insurance Dataset]</b></a> adalah data yang mengandung informasi peserta asuransi medis. Tujuan dari projek ini adalah <b>untuk memprediksi besaran tagihan yang musti dibayarkan kepada pihak asuransi </b> berdasarkan data-data peserta.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493f8370",
   "metadata": {},
   "source": [
    "### 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f411199a",
   "metadata": {},
   "source": [
    "Tahapan-tahapan yang dapat dilakukan pada EDA antara lain:\n",
    "\n",
    "> - Melihat tipe data, missing value dan data duplikat\n",
    "> - Melihat deskripsi statistik data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a739abc",
   "metadata": {},
   "source": [
    "#### 2.1 Tipe Data, Missing Value dan Duplikat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c588855",
   "metadata": {},
   "source": [
    "##### `1ï¸âƒ£` Tipe Data\n",
    "\n",
    "Tipe data yang tepat sangat penting sebelum membangun model machine learning. **Kesalahan tipe data dapat menyebabkan misinterpretasi oleh model dan menurunkan performanya.**\n",
    "\n",
    "Contohnya, jika kolom numerik masih dalam bentuk string, model tidak dapat melakukan operasi matematika dan menghasilkan error.\n",
    "\n",
    "Mari kita melihat dan menyesuaikan tipe data dari dataset kita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b20cebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# melihat tipe data tiap kolom\n",
    "insurance.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff76517",
   "metadata": {},
   "source": [
    "> Terlihat bahwa prediktor `sex`, `smoker`, dan `region` memiliki tipe data `object`. Kita perlu mengubahnya menjadi data `category` menggunakan fungsi `.astype()` yang sudah disediakan oleh python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fe49e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list kolom yang akan dijadikan kategori\n",
    "cat_features = ['sex', 'smoker', 'region']\n",
    "\n",
    "# mengubah tipe data\n",
    "insurance[cat_features] = insurance[cat_features].astype('category')\n",
    "\n",
    "# menampilkan tipe data\n",
    "insurance.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d0d3bd",
   "metadata": {},
   "source": [
    "##### `2ï¸âƒ£` Missing Value\n",
    "\n",
    "Missing value dapat terjadi karena berbagai alasan. Hal ini dapat memengaruhi performa model atau bahkan menggagalkan proses pemodelan. Oleh karena itu, penting untuk menangani missing value sebelum membangun model.\n",
    "\n",
    " ðŸ”Ž **Menangani Missing Value**\n",
    "\n",
    "Untuk treatment missing values sebenarnya ada beberapa cara umum yang bisa digunakan. Antara lain:\n",
    "\n",
    "> - **Imputasi:** Mengisi nilai yang hilang dengan nilai lain: Menggunakan metode `.fillna()`\n",
    "> - **Drop:** Menghapus observasi yang memiliki nilai missing: Menggunakan metode `.dropna()`. Namun jika nilai missing > 5%, maka tidak disarankan menggunakan metode ini."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65de3ea",
   "metadata": {},
   "source": [
    "Metode imputasi bisa berbeda tergantung jenis tipe datanya. Berikut detail metode imputasi yang bisa digunakan.\n",
    "\n",
    "**Untuk kolom categorical:**\n",
    "\n",
    "> - Isi menggunakan nilai lainnya seperti `other` atau `missing`\n",
    "> - Isi menggunakan nilai terbanyak yg muncul (`mode`)\n",
    "\n",
    "**Untuk kolom numerical:**\n",
    "\n",
    "> - Isi menggunakan nilai tengah seperti `mean` atau `median`\n",
    "> - Isi dengan nilai 0\n",
    "\n",
    "**Untuk kolom datetime:**\n",
    "\n",
    "> - Menggunakan metode `bfill` : melakukan imputasi dari bawah ke atas\n",
    "> - Menggunakan metode `ffill` : melakukan imputasi dari atas ke bawah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab4784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# menampilkan missing value tiap kolom\n",
    "insurance.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5b58c7",
   "metadata": {},
   "source": [
    "> Karena tidak ada nilai yang hilang, maka lanjut ke tahap berikutnya."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10664a55",
   "metadata": {},
   "source": [
    "##### `3ï¸âƒ£` Duplicate Value\n",
    "\n",
    "Nilai duplikat adalah baris yang memiliki kesamaan nilai dengan 1 atau lebih baris yang lain. **Nilai duplikat dalam dataset dapat menyebabkan hasil pemodelan yang bias dan tidak akurat karena mementingkan nilai-nilai yang duplikat.** Oleh karena itu, penting untuk mengidentifikasi nilai duplikat sebelum membangun model machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902e6be7",
   "metadata": {},
   "source": [
    "Untuk melihat jumlah data duplikat pada dataset, kita bisa menggunakan fungsi `.duplicated().sum()`. Sedangkan untuk melihat mana saja yang duplit, bisa menggunakan subsetting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b47b97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# menampilkan jumlah data yang duplikat\n",
    "insurance.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9073fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# melihat data yang duplikat menggunakan subsetting\n",
    "insurance[insurance.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c63032",
   "metadata": {},
   "source": [
    "Untuk menghapus data duplikat, bisa menggunakan fungsi `.drop_duplicate()`.\n",
    "\n",
    "Ada beberapa parameter pada fungsi tersebut, diantaranya yaitu:\n",
    "- `subset`: identifikasi duplikat berdasarkan kolom tertentu. Default: menggunakan semua kolom.\n",
    "- `keep`: menentukan data duplikat mana yang akan dipertahankan. Ada 3 pilihan yaitu:\n",
    "  - `first`: hapus semua duplikat kecuali data pertama (**default**).\n",
    "  - `last`: hapus semua duplikat kecuali data terakhir.\n",
    "  - `False`: hapus semua data duplikat.\n",
    "- `inplace`: apakah ingin langsung mengupdate dataframe?\n",
    "  - `True`: langsung update dataframe tanpa menyimpan ulang.\n",
    "  - `False`: tidak langsung update dataframe (**default**).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fef4d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# menghapus data duplikat dan mempertahankan data pertama\n",
    "insurance = insurance.drop_duplicates()\n",
    "insurance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d11f858",
   "metadata": {},
   "source": [
    "#### Quiz 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad569a0c",
   "metadata": {},
   "source": [
    "#### 2.2 Melihat Deskripsi Statistik Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9a04c6",
   "metadata": {},
   "source": [
    "___\n",
    "1. Menggunakan dataframe `insurance`, berapa rata-rata umur peserta asuransi?\n",
    "\n",
    "> Hint : Anda mungkin membutuhkan method `describe()` untuk melihat statistik data.\n",
    "\n",
    "- [ ] 39 tahun\n",
    "- [ ] 51 tahun\n",
    "- [ ] 64 tahun\n",
    "\n",
    "<!-- \n",
    "\n",
    "Reference answer :\n",
    "\n",
    "```python\n",
    "# melihat statistik dataset\n",
    "insurance.describe()\n",
    "```\n",
    "\n",
    "Jadi rata-rata umur peserta asuransi yaitu 39 tahun.\n",
    "\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739f339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9dbeeb",
   "metadata": {},
   "source": [
    "___\n",
    "2. Menggunakan data pada nomor 1, berapa rata-rata jumlah anak yang didaftarkan asuransi?\n",
    "\n",
    "- [ ] 1 anak\n",
    "- [ ] 2 anak\n",
    "- [ ] 3 anak\n",
    "\n",
    "<!-- \n",
    "\n",
    "Berdasarkan data statistik pada nomor 1, rata-rata jumlah anak yang didaftarkan asuransi yaitu 1.\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35de558",
   "metadata": {},
   "source": [
    "___\n",
    "3. Kebanyakan peserta asuransi tinggal di daerah mana?\n",
    "\n",
    "> Hint : Anda mungkin membutuhkan method `include()` untuk melihat statistik data pada data kategorik.\n",
    "\n",
    "- [ ] southeast\n",
    "- [ ] northeast\n",
    "- [ ] northwest\n",
    "\n",
    "<!-- \n",
    "\n",
    "Reference answer :\n",
    "\n",
    "```python\n",
    "# menampilkan data statistik untuk tipe data kategorikal\n",
    "insurance.describe(include='category')\n",
    "```\n",
    "\n",
    "Sejumlah 364 peserta asuransi tinggal di daerah southeast.\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f229341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5c9af2",
   "metadata": {},
   "source": [
    "___\n",
    "4. Berdasarkan data nomor 3, berapa peserta yang aktif merokok?\n",
    "\n",
    "- [ ] 1063 peserta\n",
    "- [ ] 364 peserta\n",
    "- [ ] 274 peserta\n",
    "\n",
    "<!-- \n",
    "\n",
    "Sejumlah 1063 dari 1337 peserta asuransi bukanlah perokok. Jadi yang aktif merokok sebanyak 274 peserta.\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b5a4c9",
   "metadata": {},
   "source": [
    "### 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bf19fe",
   "metadata": {},
   "source": [
    "Data preprocessing merupakan proses untuk membersihkan data dari data mentah menjadi data yang baik dan lengkap untuk proses modeling. Data yang bersih dan lengkap akan menghasilkan model machine learning yang efektif dan efisien serta memiliki performa yang lebih baik.\n",
    "\n",
    "Proses ini bertujuan untuk mengurangi waktu komputasi dan resource yang dibutuhkan saat proses pembuatan model dan meningkatkan performa model machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f38207",
   "metadata": {},
   "source": [
    "Tahapan-tahapan yang dapat dilakukan pada data preprocessing antara lain:\n",
    "\n",
    "> - Menangani data outliers\n",
    "> - Menangani data kategorikal\n",
    "> - Membagi dataset menjadi data train dan test\n",
    "> - Melakukan scaling data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410cf866",
   "metadata": {},
   "source": [
    "#### 3.1 Handling Numerical Data: Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d4ccd1",
   "metadata": {},
   "source": [
    "Outlier adalah observasi dengan nilai yang jauh berbeda dari mayoritas data. Hal ini dapat disebabkan oleh kesalahan input, anomali, atau kesalahan perhitungan. Menangani outlier penting dalam pemodelan machine learning karena dapat memengaruhi performa model.\n",
    "\n",
    " ðŸ”Ž **Menangani Outliers**\n",
    " \n",
    "Ada beberapa cara untuk menangani outliers:\n",
    "1. **Remove outlier**: Menghilangkan dan menghapus keseluruhan outlier. Metode ini tidak disarankan jika jumlah outliers > 5% dari total data.\n",
    "2. **Imputasi**: Mengganti nilai outliers dengan nilai yang diperbolehkan (sesuai kebutuhan).\n",
    "3. ***Scaling***: Teknik untuk mentrasformasi sehingga nilai-nilai outlier ini tidak akan berpengaruh besar terhadap hasil analisis. Teknik scaling bermacam-macam, seperti standarisasi, normalisasi, min-max scaler dan lain sebagainya.\n",
    "\n",
    "\n",
    "Mari kita identifikasi nilai outlier pada data kita dengan menggunakan boxplot:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336a96d1",
   "metadata": {},
   "source": [
    "#### Quiz 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fc55b8",
   "metadata": {},
   "source": [
    "___\n",
    "1. Menggunakan menggunakan boxplot pada kolom numerik, kolom mana yang datanya paling tersebar?\n",
    "\n",
    "> Hint : Anda harus mendefinisikan kolom mana saja yang bertipe numerik (selain target) lalu buat boxplot untuk kolom tersebut.\n",
    "\n",
    "- [ ] Age\n",
    "- [ ] BMI\n",
    "- [ ] Children\n",
    "\n",
    "<!-- \n",
    "\n",
    "Reference answer :\n",
    "\n",
    "```python\n",
    "# list kolom numerik\n",
    "num_features = ['age', 'bmi', 'children']\n",
    "\n",
    "# visualisasi boxplot\n",
    "insurance.boxplot(column=num_features)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Kolom age memiliki box yang paling lebar di antara kolom bmi dan children. Hal ini menandakan bahwa kolom age memiliki data yang paling tersebar (ditandai dengan nilai standar deviasi yang paling tinggi di antara kolom bmi dan children).\n",
    "\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdfc25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0758d7ff",
   "metadata": {},
   "source": [
    "> ðŸ’¡ **INSIGHT:** Dari visualisasi boxplot di atas terlihat adanya outlier pada kolom `bmi` dan terlihat sedikit. Mari kita lakukan observasi lanjutan untuk mengetahui jumlah outlier dan apakah memungkinkan untuk dihapus atau tidak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be89d8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cek total data sebelum penghapusan outlier\n",
    "insurance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b8d638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghitung Q1 (kuartil pertama) dan Q3 (kuartil ketiga)\n",
    "Q1 = insurance['bmi'].quantile(0.25)\n",
    "Q3 = insurance['bmi'].quantile(0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4801a76",
   "metadata": {},
   "source": [
    "___\n",
    "2. Menggunakan metode IQR, berapa batas atas untuk kolom bmi?\n",
    "\n",
    "> Hint : Anda mungkin perlu menghitung nilai IQR dan menggunakan formula = Q3 + 1.5 * IQR,\n",
    "\n",
    "- [ ] 48.05\n",
    "- [ ] 47.55\n",
    "- [ ] 47.31\n",
    "\n",
    "<!-- \n",
    "\n",
    "Reference answer :\n",
    "\n",
    "```python\n",
    "# Hitung nilai IQR\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Mendefinisikan batas bawah dan atas\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Melihat nilai batas atas\n",
    "print(upper_bound)\n",
    "```\n",
    "\n",
    "Dengan menggunakan formula Q3 + 1.5 * IQR, maka batas atas kolom bmi yaitu 47.31\n",
    "\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfad851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52116a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# menghitung jumlah outlier pada kolom bmi\n",
    "outlier_bmi = (insurance['bmi'] > upper_bound).sum()\n",
    "\n",
    "# menampilkan jumlah outlier pada kolom bmi\n",
    "print(f\"Outlier kolom BMI: {outlier_bmi}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90204d3",
   "metadata": {},
   "source": [
    "> Karena jumlah outlier sedikit, maka kita bisa gunakan metode yang pertama yaitu menghapus outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5735f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mempertahankan data yang memiliki nilai diantara batas atas dan batas bawah\n",
    "kondisi_1 = (insurance['bmi'] >= lower_bound)\n",
    "kondisi_2 = (insurance['bmi'] <= upper_bound)\n",
    "\n",
    "# lakukan subsetting berdasarkan 2 kondisi di atas\n",
    "insurance = insurance[kondisi_1 & kondisi_2]\n",
    "\n",
    "# melihat data setelah dihapus outlier\n",
    "insurance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a739df",
   "metadata": {},
   "source": [
    "> Setelah outlier dihapus, jumlah data berkurang dari yang semula 1.337 data menjadi 1.328 data. Ada 9 data yang dihapus (outlier)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cc512b",
   "metadata": {},
   "source": [
    "#### 3.2 Handling Categorical Data\n",
    "\n",
    "Model machine learning hanya bisa belajar dari data berupa angka. Jadi jika ada prediktor yang memilili tipe data bukan angka, perlu diubah terlebih dahulu ke bentuk angka. \n",
    "\n",
    "Data kategorik dibagi menjadi 2 jenis yaitu **nominal** (tidak memiliki urutan) dan **ordinal** (memiliki urutan). Masin-masing jenis memiliki perlakukan yang berbeda dalam menanganinya.\n",
    "\n",
    "- **Nominal** $\\rightarrow$ menggunakan *dummy variable encoding* dengan fungsi `pd.get_dummies()`.\n",
    "- **Ordinal** $\\rightarrow$ menggunakan *ordinal encoding* dengan fungsi `.cat.rename_categories()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5331e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cek data\n",
    "insurance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb7817e",
   "metadata": {},
   "source": [
    "Kolom kategorikal:\n",
    "- Nominal $\\rightarrow$ Sex, smoker, region.\n",
    "- Ordinal $\\rightarrow$ Tidak ada.\n",
    "\n",
    "Karena tipe ordinal tidak ada, mari kita gunakan metode *dummy varible encoding* untuk tipe nominal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03eb0315",
   "metadata": {},
   "source": [
    "Untuk melakukan **Dummy Variable Encoding** kita menggunakan `pd.get_dummies()` dengan memasukkan kolom yang ingin kita ubah. Adapun parameter antara lain:\n",
    "\n",
    "- `data`: data yang ingin diubah menjadi numerikal\n",
    "\n",
    "- `columns`: list nama kolom yang akan dilakukan dummy variable encoding\n",
    "\n",
    "- `drop_first`: Drop salah satu kolom (kolom pertama). Default False (Tidak ada kolom di drop). True agar kolom hasil dummies tidak rendundan.\n",
    "\n",
    "- `dtype` : Mengubah tipe data hasil encoding menjadi suatu tipe data\n",
    "\n",
    "Dokumentasi `pd.get_dummies()` dapat diakses [di sini](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html)\n",
    "\n",
    "Mari kita coba menerapkan **Dummy Variable Encoding** untuk kolom yang telah kita disepakati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df77033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list prediktor yang memiliki tipe nominal\n",
    "nominal_features = ['sex', 'smoker', 'region']\n",
    "\n",
    "# implementasi pd.get_dummies\n",
    "insurance = pd.get_dummies(insurance, columns = nominal_features, drop_first=True, dtype='int64')\n",
    "insurance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb77b0e8",
   "metadata": {},
   "source": [
    "#### 3.3 Train-Test Splitting (*Cross Validation*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cd0808",
   "metadata": {},
   "source": [
    "Untuk memahami performa model, membagi dataset menjadi training data dan testing data adalah strategi yang baik dengan menggunakan fungsi `train_test_split()`. Metode ini dikenal dengan istilah *Cross Validation* yang digunakan untuk mengetahui kemampuan model memprediksi data baru.\n",
    "\n",
    "Pisahkan dataset dengan menggunakan fungsi `train_test_split()`. Anda harus melewati 3 parameter `features`, `target`, dan `test_size`. Selain itu, Anda dapat menggunakan `random_state` untuk memilih record secara acak."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb8161a",
   "metadata": {},
   "source": [
    "Kita dapat menggunakan `train_test_split` dengan beberapa parameter sebagai berikut.\n",
    "- `*arrays`: dataframe yang kita gunakan (dipisah , untuk yang prediktor dan target variable)\n",
    "- `test_size`: jumlah persentase dari data yang akan digunakan sebagai data test\n",
    "- `train_size`: jumlah persentase dari data yang akan digunakan sebagai data test (akan otomatis terisi jika `test_size` diberi nilai)\n",
    "- `random_state`: nilai random number generator (RNG). Jika kita memasukkan suatu nilai integer untuk parameter ini maka akan menghasilkan hasil yang sama untuk nilai yang sama. Jika kita mengubah nilainya, maka hasilnya akan berbeda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc42ddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# memilih kolom target\n",
    "target = 'charges'\n",
    "\n",
    "# menyimpan data kolom target ke dalam variabel y\n",
    "y = insurance[target]\n",
    "\n",
    "# menghapus kolom target sehingga tersisa kolom prediktor dan dimasukkan ke variabel X\n",
    "X = insurance.drop(columns=[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add50fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.20,\n",
    "                                                    random_state = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faab2d0",
   "metadata": {},
   "source": [
    "#### Quiz 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de29ede",
   "metadata": {},
   "source": [
    "___\n",
    "1. Berdasarkan proses `train_test_split`, berapa % data yang digunakan untuk menguji model?\n",
    "\n",
    "- [ ] 20\n",
    "- [ ] 70\n",
    "- [ ] 80\n",
    "\n",
    "<!-- \n",
    "\n",
    "Dataset insurance dibagi menjadi data train dan data test dengan proporsi 80% data train dan 20% data test. Jawaban = 20%\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3519c415",
   "metadata": {},
   "source": [
    "___\n",
    "2. Data apa saja yang digunakan untuk proses `train_test_split`?\n",
    "\n",
    "- [ ] X dan y\n",
    "- [ ] X_train dan y_train\n",
    "- [ ] X_test dan y_test\n",
    "\n",
    "<!-- \n",
    "\n",
    "Untuk proses splitting dataset, digunakan data dari variabel X yang berisi prediktor dan y yang berisi data target. X_train, X_test, y_train, dan y_test merupakan hasil setelah split dataset.\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe5e5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cek dimensi data train\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419243e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cek dimensi data test\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49093fa4",
   "metadata": {},
   "source": [
    "#### 3.4 Scaling (*Z Score Nomalization*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e440d213",
   "metadata": {},
   "source": [
    "Proses scaling dilakukan untuk menyeragamkan skala data antar prediktor. Hal ini penting dilakukan karena jika skala data antar prediktor tidak seragam, maka model machine learning akan bias (lebih memperhatikan) prediktor yang memiliki skala yang lebih besar. Hal ini akan membuat prediktor lain yang memiliki skala lebih kecil seakan-akan tidak memiliki pengaruh terhadap model dan akan membuat performa model tidak maksimal.\n",
    "\n",
    "Metode scaling sangat banyak sekali seperti standarisasi dan normalisasi. Untuk kasus ini kita akan menggunakan metode standarisasi Z score menggunakan fungsi `StandardScaler` dari library `sklearn` yang membuat data kita memiliki nilai `mean = 0` dan `standar deviasi = 1`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6640e4f",
   "metadata": {},
   "source": [
    "#### Quiz 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9354ed5e",
   "metadata": {},
   "source": [
    "___\n",
    "1. Proses fit scaling berlaku untuk data apa saja?\n",
    "\n",
    "- [ ] X_train dan y_train\n",
    "- [ ] X_train\n",
    "- [ ] X_test\n",
    "\n",
    "<!-- \n",
    "\n",
    "Reference answer :\n",
    "\n",
    "```python\n",
    "# membuat object dari class StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# proses fit scaling\n",
    "scaler.fit(X_train[num_features])\n",
    "```\n",
    "\n",
    "Proses fit scaling hanya berlaku untuk data X_train. Hal ini dilakukan untuk mencegah kebocoran (leak) pada data test. Hal ini dilakukan agar informasi pada data test benar-benar tidak bocor/tidak diketahui saat pembuatan model sehingga hasil evaluasi model lebih dapat dipertanggung jawabkan.\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9dc1f0",
   "metadata": {},
   "source": [
    "___\n",
    "2. Proses transform scaling berlaku untuk data apa saja?\n",
    "\n",
    "- [ ] X_train dan y_train\n",
    "- [ ] X_test dan y_test\n",
    "- [ ] X_train dan X_test\n",
    "\n",
    "<!-- \n",
    "\n",
    "Reference answer :\n",
    "\n",
    "```python\n",
    "# proses transform scaling\n",
    "X_train[num_features] = scaler.transform(X_train[num_features])\n",
    "X_test[num_features] = scaler.transform(X_test[num_features])\n",
    "```\n",
    "\n",
    "Proses transform diberlakukan untuk data X_train dan X_test. Data y_train dan y_test tidak dilakukan scaling karena merupakan kolom target.\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9273ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c040de",
   "metadata": {},
   "source": [
    "___\n",
    "3. Setelah proses scaling, berapa kolom yang tersisa dari proses tersebut?\n",
    "\n",
    "- [ ] 3\n",
    "- [ ] 8\n",
    "- [ ] 11\n",
    "\n",
    "<!-- \n",
    "\n",
    "Reference answer :\n",
    "\n",
    "```python\n",
    "# melihat data setelah proses scaling\n",
    "X_train.head()\n",
    "```\n",
    "\n",
    "Menggunakan kode di atas, terlihat bahwa setelah scaling, jumlah tetap 8. Karena proses scaling tidak menambah/mengurangi jumlah kolom. Hanya mentransformasi nilai menjadi skala yang lebih kecil.\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a36d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2204d095",
   "metadata": {},
   "source": [
    "### 4. Model Building: Support Vector Regressor (SVR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6488b57a",
   "metadata": {},
   "source": [
    "SVM walaupun lebih terkenal pada penggunaan case klasifikasi, namun sebenarnya SVM juga mampu diterapkan untuk kasus regresi dengan sangat baik (memprediksi nilai yang target variabelnya numerik). \n",
    "\n",
    "Secara simpel SVR akan menghasilkan *hyperplane* yang dapat mengikuti pola data dari target terhadap prediktor. *Hyperplane* ini yang digunakan untuk memprediksi nilai target pada data baru."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60993aae",
   "metadata": {},
   "source": [
    "#### 4.1 SVR Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ed1872",
   "metadata": {},
   "source": [
    "ðŸ”»Setelah semua proses persiapan data selesai, kini adalah saatnya untuk 'mesin' belajar dan diuji oleh data kita.\n",
    "\n",
    "Langkah-langkah membangun model SVM. \n",
    "> 1. Import library SVR dari SVM.\n",
    "> 2. Buat variabel `model_svr` untuk menyimpan hasil model `SVR()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0982ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat object SVR dari class svm\n",
    "model_svr = svm.SVR()\n",
    "\n",
    "# proses training\n",
    "model_svr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f59950",
   "metadata": {},
   "source": [
    "#### 4.2 Model Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f5e829",
   "metadata": {},
   "source": [
    "Setelah model dilatih, model siap digunakan untuk memprediksi data baru. Model akan memprediksi data test yang telah kita siapkan sebelumnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad5e8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediksi data test\n",
    "y_pred = model_svr.predict(X_test)\n",
    "\n",
    "# menampilkan 10 data hasil prediksi\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e60b0fc",
   "metadata": {},
   "source": [
    "**ðŸ’¡NOTES**: Walaupun kita sudah berhasil memprediksi, kita tetap perlu memastikan bahwa hasil prediksinya banyak yang benar / sudah sesuai dengan melakukan model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b7f19b",
   "metadata": {},
   "source": [
    "### 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47098c8",
   "metadata": {},
   "source": [
    "Setelah kita melakukan prediksi akan dilakukan evaluasi model dengan membandingkan nilai aktual dan hasil prediksi. Perbedaan antara nilai prediksi dengan nilai aktual disebut sebagai *error*, semakin kecil *error* maka semakin bagus model kita, karena nilai prediksi semakin mendekati nilai aslinya.\n",
    "\n",
    "Salah satu cara yang sering digunakan dalam menghitung error adalah MAE ***(Mean Absolute Error)***. Yaitu dengan menghitung rata-rata error untuk semua prediksi.\n",
    "\n",
    "Berikut adalah formula menghitung MAE:\n",
    "\n",
    "$$MAE = \\frac{\\sum_{i=1}^{n}\\left | y_{pred, i} - y_{real, i} \\right |}{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29adf28f",
   "metadata": {},
   "source": [
    "Mean Absolute Error (MAE): Metriks untuk regresi yang menghitung rata-rata error untuk semua prediksi.\n",
    "\n",
    "- Semakin kecil nilai MAE, semakin baik model kita\n",
    "- Semakin besar nilai MAE, semakin buruk model kita."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6318ef78",
   "metadata": {},
   "source": [
    "ðŸ”» Fungsi `mean_absolute_error()` memungkinkan kita Untuk menghitung *Mean Absolute Error*, kita dapat menggunkaan fungsi `mean_absolute_error` dari `sklearn.metrics`.\n",
    "\n",
    " Parameter yang dimasukkan adalah;\n",
    "* `y_true` : data target aktual (*ground truth*) yang akan dijadikan acuan nilai sebenarnya\n",
    "* `y_pred` : data target hasil prediksi model\n",
    "\n",
    "Dokumentasi metrik evaluasi MAE dan metrik lainnya dapat diakses [di sini](https://scikit-learn.org/stable/api/sklearn.metrics.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174c1f3b",
   "metadata": {},
   "source": [
    "> Untuk mengetahui apakah model yang Anda buat underfit, good fit, atau overfit, mari bandingkan peforma model ketika memprediksi data train dan data test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cbd200",
   "metadata": {},
   "source": [
    "#### Quiz 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5403fb",
   "metadata": {},
   "source": [
    "___\n",
    "1. Berapa nilai MAE pada data train yang dihasilkan oleh model regresi?\n",
    "\n",
    "> âœ¨ Hint: gunakan `model_svr` untuk memprediksi data train. Dengan menggunakan MAE, bandingkan nilai aktual pada data train dan hasil prediksi `model_svr`.\n",
    "\n",
    "- [ ] 8,360.92\n",
    "- [ ] 8,243.41\n",
    "- [ ] 8,110.53\n",
    "\n",
    "<!-- \n",
    "Reference answer :\n",
    "\n",
    "```python\n",
    "# prediksi data train\n",
    "y_pred_train = model_svr.predict(X_train)\n",
    "```\n",
    "\n",
    "Berdasarkan kode di atas, didapat nilai MAE pada data train sebesar 8,243.41 (dalam format Bahasa Inggris)\n",
    "\n",
    "\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b58c2af",
   "metadata": {},
   "source": [
    "Prediksi model menggunakan data train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc14715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba2266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluasi model\n",
    "mae_train = metrics.mean_absolute_error(y_train, y_pred_train)\n",
    "\n",
    "# tampilkan hasil evaluasi\n",
    "print(f\"MAE Train : {mae_train:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12980e9d",
   "metadata": {},
   "source": [
    "___\n",
    "2. Berapa nilai MAE pada data test yang dihasilkan oleh model regresi?\n",
    "\n",
    "> âœ¨ Hint: gunakan `model_svr` untuk memprediksi data test. Dengan menggunakan MAE, bandingkan nilai aktual pada data test dan hasil prediksi `model_svr`.\n",
    "\n",
    "- [ ] 8,360.92\n",
    "- [ ] 8,243.41\n",
    "- [ ] 8,110.53\n",
    "\n",
    "<!-- \n",
    "Reference answer :\n",
    "\n",
    "```python\n",
    "# prediksi data test\n",
    "y_pred_test = model_svr.predict(X_test)\n",
    "```\n",
    "\n",
    "Berdasarkan kode di atas, didapat nilai MAE pada data test sebesar 8,360.92 (dalam format Bahasa Inggris)\n",
    "\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad79838",
   "metadata": {},
   "source": [
    "Prediksi model menggunakan data test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f43db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a5ee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluasi model\n",
    "mae_test = metrics.mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "# tampilkan hasil evaluasi\n",
    "print(f\"MAE Test : {mae_test:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f12d33d",
   "metadata": {},
   "source": [
    "> âœ¨ NOTE: Untuk mengetahui apakah model sudah baik atau belum berdasarkan nilai MAE, Anda perlu membanginya dengan rentang nilai aslinya. Model regresi yang baik memiliki nilai MAE < 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e812f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# menghitung rentang nilai data train\n",
    "range_train = y_train.max() - y_train.min()\n",
    "mae_train_percent = round(mae_train / range_train * 100, 2)\n",
    "\n",
    "# menghitung rentang nilai data test\n",
    "range_test = y_test.max() - y_test.min()\n",
    "mae_test_percent = round(mae_test / range_test * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb9d8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# menampilkan perbandingan evaluasi model pada data train dan data test\n",
    "pd.DataFrame(data = {\"MAE\": [mae_train, mae_test],\n",
    "                     \"MAE (%)\": [mae_train_percent, mae_test_percent]},\n",
    "             index = [\"Data Train\", 'Data Test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7845aa6d",
   "metadata": {},
   "source": [
    "> ðŸ’¡ **INSIGHT:** Dari hasil evaluasi, dapat dikatakan bahwa model kita belum memiliki performa yang baik karena nilai MAE > 10%. Untuk memperbaiki performa, perlu kita lakukan proses tuning hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52cc6b7",
   "metadata": {},
   "source": [
    "### 6. Model Improvement: Tuning Hyperparameter SVR (Opsional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455c7d88",
   "metadata": {},
   "source": [
    "Seperti pada SVC, SVR juga memiliki *hyperparameter* yang dapat diatur untuk meningkatkan performa model.\n",
    "\n",
    "Adapun *hyperparameter* yang sering digunakan dalam model SVR antara lain:\n",
    "- `C (regularization) [default = 1, range = positive number]`: Sama seperti regularisasi pada SVC, semakin tinggi C pada SVR, maka membuat model semakin menyesuaikan data dengan lebih baik namun beresiko overfitting.\n",
    "- `kernel [default = 'rbf', option = ['rbf', 'poly', 'linear', 'sigmoid']`: Mempengaruhi bagaimana garis regresi (*hyperplane*) terbentuk, untuk data yang dapat memiliki pola linear (garis lurus) dapat menggunakan 'linear'. Untuk data-data dengan pola non-linear dapat menggunakan kernel `rbf`.\n",
    "*Note: Kebanyakan data berbentuk non-linear, sehingga sebaiknya selalu memilih kernel `rbf`*\n",
    "- `epsilon [default = 0.1, range = 0.0 - inf]` : Epsilon mengatur tingkat kesalahan yang ditoleransi oleh model. Semakin kecil nilai epsilon, maka semakin ketat batas toleransi oleh model, sehingga model lebih kompleks. Begitupun sebaliknya.\n",
    "\n",
    "Untuk hyperparameter dan penjelasan lebih detail dapat dilihat pada [dokumentasi SVR](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e22d0b",
   "metadata": {},
   "source": [
    "Mari kita coba untuk tuning model regresi kita dengan nama `model_svr_tuning`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fffafb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat model svc tuning\n",
    "model_svr_tuning = svm.SVR(C = 1000, kernel = 'rbf', epsilon=0.1)\n",
    "\n",
    "# melakukan pelatihan ulang\n",
    "model_svr_tuning.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd58ada6",
   "metadata": {},
   "source": [
    "Mari kita lihat performa model hasil tuning untuk memprediksi data train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d680950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediksi data train menggunakan model hasil tuning\n",
    "y_pred_train_tuning = model_svr_tuning.predict(X_train)\n",
    "\n",
    "# evaluasi model\n",
    "mae_train_tuning = metrics.mean_absolute_error(y_train, y_pred_train_tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfdbdcb",
   "metadata": {},
   "source": [
    "Mari kita lihat performa model hasil tuning untuk memprediksi data test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b409ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediksi data test menggunakan model hasil tuning\n",
    "y_pred_test_tuning = model_svr_tuning.predict(X_test)\n",
    "\n",
    "# evaluasi model\n",
    "mae_test_tuning = metrics.mean_absolute_error(y_test, y_pred_test_tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfec02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# menghitung rentang nilai data train\n",
    "mae_train_tuning_percent = round(mae_train_tuning / range_train * 100, 2)\n",
    "\n",
    "# menghitung rentang nilai data test\n",
    "mae_test_tuning_percent = round(mae_test_tuning / range_test * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362ae7b6",
   "metadata": {},
   "source": [
    "Mari kita lihat perbandingan performa model data data train dan test sebelum dan sesudah tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc64e1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan perbandingan evaluasi model hasil tuning pada data train dan data test\n",
    "pd.DataFrame(data = {\"MAE Train\": [mae_train, mae_test],\n",
    "                     \"MAE Train (%)\": [mae_train_percent, mae_test_percent],\n",
    "                     \"MAE Test\": [mae_train_tuning, mae_test_tuning],\n",
    "                     \"MAE Test (%)\": [mae_train_tuning_percent, mae_test_tuning_percent]},\n",
    "             index = [\"Base Model\", 'Tuning Model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b294ed57",
   "metadata": {},
   "source": [
    "**âœ¨ INSIGHT âœ¨**\n",
    "> Setelah dilakukan proses tuning, skor MAE menjadi 5%. Hal ini menandakan bahwa model hasil tuning sudah bisa dikatakan model yang baik. Model yang dihasilkan merupakan model yang **Good Fit** karena nilai MAE pada data train dan data test tidak jauh berbeda."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
