prob_default <- 11395/(13366+11395)
prob_default
# probability ke log of odds
logit(prob_default)
# bandingkan dengan coefficient
model_null$coefficients
# log(odds) -> odds
exp(-0.1595395)
# log of odds -> prob
inv.logit(-0.1595395)
head(train)
model_pay1 <- glm(
formula = gb_flag ~ pay_1,
data = train,
family = "binomial"
)
summary(model_pay1)
# log(odds) -> odds
exp(1.21814)
# log of odds
log_odds_Aya <- -0.78605 + 1.21814 * 2
log_odds_Lita <- -0.78605 + 1.21814 * 3
log_odds_Lita - log_odds_Aya
exp(log_odds_Lita - log_odds_Aya)
head(train)
model_sex <- glm(
formula = gb_flag ~ sex,
data = train,
family = "binomial"
)
summary(model_sex)
# log(odds) -> odds sexwoman
exp(-0.269531)
# peluang Aya gagal bayar
log_odds_aya <- -0.001956 + -0.269531*2
inv.logit(log_odds_aya)
# peluang Adi gagal bayar
log_odds_adi <- -0.001956 + -0.269531*1
inv.logit(log_odds_adi)
model_sp <- glm(
formula = gb_flag ~ sex + pay_1,
data = train,
family = "binomial"
)
summary(model_sp)
# odds sex
exp(-0.26658)
# odds pay_1
exp(1.21864)
model_sp$coefficients
# your code here
log_ofodds_Adi <- -0.6303408 + (-0.2665808*1) + (1.2186424*3)
log_ofodds_Adi
# mengubah log of odss Adi ke bentuk Peluang
inv.logit(log_ofodds_Adi)
model_all <- glm(
formula = gb_flag ~ .,
data = train,
family = "binomial"
)
summary(model_all)
model_step <- step(
object = model_all,
direction = "backward"
)
summary(model_step)
# residual deviance
model_null$deviance
model_pay1$deviance
model_sex$deviance
model_sp$deviance
model_all$deviance
model_step$deviance
# aic
model_null$aic
model_pay1$aic
model_sex$aic
model_sp$aic
model_all$aic
# cek multicollinearity model_no_w
library(car)
vif(model_all)
df_perfsep <- readRDS("data/data_dummy.RDS")
model_perfsep <- glm(gb_flag ~ ., data = df_perfsep, family = "binomial")
summary(model_perfsep)
table(df_perfsep$limit_bal, df_perfsep$gb_flag)
# log of odds
predict(
object = model_all,
newdata = head(test),
type = "link"
)
# probability
predict(
object = model_all,
newdata = head(test),
type = "response"
)
# ubah peluang menjadi label prediksi
p_gbflag <- predict(
object = model_all,
newdata = head(test),
type = "response"
)
ifelse(p_gbflag > 0.5, yes = 1, no = 0)
test$pred_risk <- predict(model_all,
newdata = test,
type = "response") #probability
head(test, 10)
# ifelse(kondisi, benar, salah)
test$pred_label <-  ifelse(test$pred_risk > 0.5, "1", "0")
head(test,10)
# lihat hasil prediksi
test %>%
select(gb_flag, # label
pred_risk, # peluang
pred_label) %>% # hasil prediksi (label)
head(15)
table(
prediksi = test$pred_label,
aktual = test$gb_flag
)
knitr::include_graphics("img/tnfp.PNG")
# confusion matrix
library(caret)
confusionMatrix(
data = as.factor(test$pred_label),
reference = test$gb_flag,
positive = "1"
)
table(
prediksi = test$pred_label,
aktual = test$gb_flag
)
# total data: nrow(test)
(2155 + 2852)/nrow(test)
table(
prediksi = test$pred_label,
aktual = test$gb_flag
)
2155/(2155+717)
2155/(2155+467)
# meningkatkan recall
test$pred_label_new <- ifelse(test$pred_risk > 0.3,
yes = 1,
no = 0)
confusionMatrix(data = as.factor(test$pred_label_new),
reference = test$gb_flag,
positive = "1")
knitr::include_graphics("img/KNN.png")
data_clean %>%
head()
# code here
knn_data <- data_clean %>%
select(-sex, -education, -marriage)
head(knn_data)
library(rsample)
# intuisi set seed: mengunci kerandoman data
RNGkind(sample.kind = "Rounding")
set.seed(123)
# membuat binary split data menjadi set data training dan testing dengan proporsi 80:20
splitter <- initial_split(data = knn_data, prop = 0.8)
# splitting
train_knn <- training(splitter)
test_knn <- testing(splitter)
# recheck class balance
table(train_knn$gb_flag) %>%
prop.table()
summary(train_knn)
normalize <- function(x){
return (
(x - min(x))/(max(x) - min(x))
)
}
# contoh:
normalize(c(1, 2, 4, 7, 20, 1000))
# contoh:
scale(c(1, 2, 4, 7, 20, 1000))
library(dplyr)
# prediktor
credit_train_x <- train_knn %>% select(-gb_flag)
credit_test_x <- test_knn %>% select(-gb_flag)
# target
credit_train_y <- train_knn$gb_flag
credit_test_y <- test_knn$gb_flag
# scaling data
# train
credit_train_xs <- scale(credit_train_x)
# test
credit_test_xs <- scale(credit_test_x,
center = attr(credit_train_xs, "scaled:center"),
scale = attr(credit_train_xs, "scaled:scale"))
# find optimum k: akar dari jumlah data (jumlah baris)
sqrt(nrow(credit_train_xs))
library(class) # package untuk fungsi `knn()`
credit_knn <- knn(
train = credit_train_xs,
test = credit_test_xs,
cl = credit_train_y,
k = 157 #mengambil 157 tetangga terdekat
)
head(credit_knn)
head(credit_test_y)
# menyimpan ke dalam data test
test_knn$pred_label <- credit_knn
test_knn
# confusion matrix
library(caret)
# Confusion matrix untuk model K-NN
confusionMatrix(
data = as.factor(test_knn$pred_label),
reference = test_knn$gb_flag,
positive = "1"
)
# Confusion Matrix model Logistic Regression
confusionMatrix(
data = as.factor(test$pred_label),
reference = test$gb_flag,
positive = "1"
)
knitr::include_graphics("img/karakter.PNG")
# clear-up the environment
rm(list = ls())
# chunk options
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE,
fig.align = "center",
comment = "#>"
)
options(scipen = 10)
knitr::include_graphics("assets/Classification 1.png")
library(dplyr) # for wrangling
library(inspectdf) # for EDA
library(gtools) # for ML model & assumption
library(caret) # for ML model & evaluation
library(readxl)
knitr::include_graphics("img/lin_reg_vs_log_reg.png")
# read data
data <- read_xlsx("data/credit_taiwan.xlsx")
head(data)
# your code here
data_clean <- data %>%
select(-id)
head(data_clean)
# cek struktur data
str(data_clean)
data_clean <- data_clean %>%
mutate(
sex = as.factor(sex),
marriage = as.factor(marriage),
education = as.factor(education),
gb_flag = as.factor(gb_flag)
)
glimpse(data_clean)
# your code here
data_clean %>%
inspect_cat()
data_clean %>%
inspect_num()
knitr::include_graphics("img/test-train.png")
library(rsample)
# intuisi set seed: mengunci kerandoman data
RNGkind(sample.kind = "Rounding")
set.seed(123)
# membuat binary split data menjadi set data training dan testing dengan proporsi 80:20
splitter <- initial_split(data = data_clean, prop = 0.8)
# splitting
train <- training(splitter) #80% dari data
test <- testing(splitter) #20% dari data
# your code here
table(train$gb_flag) %>%
prop.table()
train$gb_flag %>%
head()
p_delay <- 20/100
p_delay
p_ontime <- 80/100
p_ontime
odds_ontime <- 0.8/0.2
odds_ontime
odds_delay <- 0.2/0.8
odds_delay
log(odds_ontime)
log(odds_delay)
knitr::include_graphics("img/prob_to_logofodds.png")
# gunakan fungsi eksponen `exp()`
exp(1.386294)
# odds ke peluang
3.999999/(1+3.999999)
# mengubah log of odds menjadi probability
logit(p_ontime)
inv.logit(1.386294)
model_null <- glm(
formula = gb_flag ~ 1,
data = train,
family = "binomial"
)
summary(model_null)
# tabel frekuensi target variabel
table(train$gb_flag)
# probability debitur default
prob_default <- 11395/(13366+11395)
prob_default
# probability ke log of odds
logit(prob_default)
# bandingkan dengan coefficient
model_null$coefficients
# log(odds) -> odds
exp(-0.1595395)
# log of odds -> prob
inv.logit(-0.1595395)
head(train)
model_pay1 <- glm(
formula = gb_flag ~ pay_1,
data = train,
family = "binomial"
)
summary(model_pay1)
# log(odds) -> odds
exp(1.21814)
# log of odds
log_odds_Aya <- -0.78605 + 1.21814 * 2
log_odds_Lita <- -0.78605 + 1.21814 * 3
log_odds_Lita - log_odds_Aya
exp(log_odds_Lita - log_odds_Aya)
head(train)
model_sex <- glm(
formula = gb_flag ~ sex,
data = train,
family = "binomial"
)
summary(model_sex)
# log(odds) -> odds sexwoman
exp(-0.269531)
# peluang Aya gagal bayar
log_odds_aya <- -0.001956 + -0.269531*2
inv.logit(log_odds_aya)
# peluang Adi gagal bayar
log_odds_adi <- -0.001956 + -0.269531*1
inv.logit(log_odds_adi)
model_sp <- glm(
formula = gb_flag ~ sex + pay_1,
data = train,
family = "binomial"
)
summary(model_sp)
# odds sex
exp(-0.26658)
# odds pay_1
exp(1.21864)
model_sp$coefficients
# your code here
log_ofodds_Adi <- -0.6303408 + (-0.2665808*1) + (1.2186424*3)
log_ofodds_Adi
# mengubah log of odss Adi ke bentuk Peluang
inv.logit(log_ofodds_Adi)
model_all <- glm(
formula = gb_flag ~ .,
data = train,
family = "binomial"
)
summary(model_all)
model_step <- step(
object = model_all,
direction = "backward"
)
summary(model_step)
# residual deviance
model_null$deviance
model_pay1$deviance
model_sex$deviance
model_sp$deviance
model_all$deviance
model_step$deviance
# aic
model_null$aic
model_pay1$aic
model_sex$aic
model_sp$aic
model_all$aic
# cek multicollinearity model_no_w
library(car)
vif(model_all)
df_perfsep <- readRDS("data/data_dummy.RDS")
model_perfsep <- glm(gb_flag ~ ., data = df_perfsep, family = "binomial")
summary(model_perfsep)
table(df_perfsep$limit_bal, df_perfsep$gb_flag)
# log of odds
predict(
object = model_all,
newdata = head(test),
type = "link"
)
# probability
predict(
object = model_all,
newdata = head(test),
type = "response"
)
# ubah peluang menjadi label prediksi
p_gbflag <- predict(
object = model_all,
newdata = head(test),
type = "response"
)
ifelse(p_gbflag > 0.5, yes = 1, no = 0)
test$pred_risk <- predict(model_all,
newdata = test,
type = "response") #probability
head(test, 10)
# ifelse(kondisi, benar, salah)
test$pred_label <-  ifelse(test$pred_risk > 0.5, "1", "0")
head(test,10)
# lihat hasil prediksi
test %>%
select(gb_flag, # label
pred_risk, # peluang
pred_label) %>% # hasil prediksi (label)
head(15)
table(
prediksi = test$pred_label,
aktual = test$gb_flag
)
knitr::include_graphics("img/tnfp.PNG")
# confusion matrix
library(caret)
confusionMatrix(
data = as.factor(test$pred_label),
reference = test$gb_flag,
positive = "1"
)
table(
prediksi = test$pred_label,
aktual = test$gb_flag
)
# total data: nrow(test)
(2155 + 2852)/nrow(test)
table(
prediksi = test$pred_label,
aktual = test$gb_flag
)
2155/(2155+717)
2155/(2155+467)
# meningkatkan recall
test$pred_label_new <- ifelse(test$pred_risk > 0.3,
yes = 1,
no = 0)
confusionMatrix(data = as.factor(test$pred_label_new),
reference = test$gb_flag,
positive = "1")
knitr::include_graphics("img/KNN.png")
data_clean %>%
head()
# code here
knn_data <- data_clean %>%
select(-sex, -education, -marriage)
head(knn_data)
library(rsample)
# intuisi set seed: mengunci kerandoman data
RNGkind(sample.kind = "Rounding")
set.seed(123)
# membuat binary split data menjadi set data training dan testing dengan proporsi 80:20
splitter <- initial_split(data = knn_data, prop = 0.8)
# splitting
train_knn <- training(splitter)
test_knn <- testing(splitter)
# recheck class balance
table(train_knn$gb_flag) %>%
prop.table()
summary(train_knn)
normalize <- function(x){
return (
(x - min(x))/(max(x) - min(x))
)
}
# contoh:
normalize(c(1, 2, 4, 7, 20, 1000))
# contoh:
scale(c(1, 2, 4, 7, 20, 1000))
library(dplyr)
# prediktor
credit_train_x <- train_knn %>% select(-gb_flag)
credit_test_x <- test_knn %>% select(-gb_flag)
# target
credit_train_y <- train_knn$gb_flag
credit_test_y <- test_knn$gb_flag
# scaling data
# train
credit_train_xs <- scale(credit_train_x)
# test
credit_test_xs <- scale(credit_test_x,
center = attr(credit_train_xs, "scaled:center"),
scale = attr(credit_train_xs, "scaled:scale"))
# find optimum k: akar dari jumlah data (jumlah baris)
sqrt(nrow(credit_train_xs))
# find optimum k: akar dari jumlah data (jumlah baris)
sqrt(nrow(credit_train_xs))
credit_train_xs
# find optimum k: akar dari jumlah data (jumlah baris)
sqrt(nrow(credit_train_xs))
credit_test_xs
library(class) # package untuk fungsi `knn()`
credit_knn <- knn(
train = credit_train_xs,
test = credit_test_xs,
cl = credit_train_y,
k = 157 #mengambil 157 tetangga terdekat
)
head(credit_knn)
# find optimum k: akar dari jumlah data (jumlah baris)
sqrt(nrow(credit_train_xs))
