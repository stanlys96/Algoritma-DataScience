---
title: "Kuis Neural Network"
author: "Team Algoritma"
date: "`r format(Sys.Date(), '%B %e, %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Kuis Neural Network

Kuis ini merupakan bagian dari proses penilaian *Algoritma Academy*. Selamat Anda telah menyelesaikan materi *Neural Network*! Kami akan melakukan penilaian berupa kuis untuk menguji materi yang sudah dipelajari. Pengerjaan Kuis diharapkan dapat dilakukan di dalam kelas, silakan hubungi tim instruktur kami jika Anda melewatkan kesempatan untuk mengambilnya di kelas.

Untuk menyelesaikan kuis ini, Anda perlu untuk membuat model klasifikasi untuk mengklafisikasikan kategori dari gambar bahasa isyarat (sign language) menggunakan algoritma Neural Network menggunakan framework `keras` dengan langkah-langkah berikut:

# 1 Persiapan Data

Mari kita mulai pengalaman penerapan neural network kita dengan menyiapkan dataset sebagai langkah pertama. Anda akan menggunakan `sign-language-mnist` dataset yang dapat diunduh pada [laman berikut](https://www.kaggle.com/datamunge/sign-language-mnist). Data yang harus diunduh, yaitu `sign-mnist-train.csv` sebagai data train dan `sign-mnist-test.csv` sebagai data test, kemudian simpan kedua data tersebut ke dalam folder kuis yang Anda gunakan *(Neural-Network-v2)*. Kedua data tersebut menyimpan gambar bahasa isyarat (sign language) berukuran 28 x 28 pixel untuk 24 kategori yang berbeda. 

**1.1 Panggil library dan Baca data**

Silakan panggil package berikut:

```{r warning=FALSE, message=FALSE}
library(dplyr)
library(keras)
library(caret)
```

Pada tahap ini, silakan baca dan periksa data `sign-mnist-train.csv` dan `sign-mnist-test.csv`, kemudian simpan data tersebut sebagai `sign_train` dan `sign_test`. 

```{r}
# your code here
sign_train <- 
sign_test <- 
```

Periksa data `sign_train` dengan menggunakan `head()`.

```{r}
# your code here

```

`sign_train` terdiri dari 27455 observasi dan 785 variabel (1 target and 784 prediktor). Setiap prediktor merepresentasikan pixel dari gambar.

**1.2 Memperbaiki kategori pada target variabel**

Periksa kategori pada target variabel baik pada data `sign_train` dan `sign_test` degan menggunakan fungsi `unique()`

```{r}
# your code here

```

Kita perlu memperbaiki kategori pada target variabel baik pada data `sign_train` dan `sign_test`. Karena label 9 dan 25 tidak ada, kita dapat mengurangkan dengan 1 semua label yang bernilai lebih besar dari 9. Dengan cara ini, label kita menjadi semua bilangan bulat dari 0 hingga 23. Anda dapat memanfaatkan fungsi `mutate()` dan `ifelse()` untuk memperbaiki kategori pada target variabel baik pada data `sign_train` dan `sign_test`.

Gunakan *code* di bawah ini untuk memperbaiki kategori target variabel pada data `sign_train` dan `sign_test`.

```{r}
sign_train <- sign_train %>% 
  mutate(label = ifelse(label > 9, label-1, label))

sign_test <- sign_test %>% 
  mutate(label = ifelse(label > 9, label-1, label))
```

**1.3 Memisahkan prediktor dan target, mengubah data ke dalam matriks, dan features scaling**

Data berisi nilai pixel yang disimpan dalam data frame. Namun, kita harus memisahkan prediktor dan target untuk data `sign_train` dan `sign_test` dan menyimpannya ke dalam `train_x`, `train_y`, `test_x`, dan `test_y`. Anda dapat memanfaatkan fungsi `select()` untuk memisahkan prediktor dan target pada data `sign_train` dan `sign_test`. 

Setelah itu, data `train_x`, `train_y`, `test_x`, dan `test_y` harus diubah menjadi matriks. Silahkan ubah data menjadi format matrix menggunakan fungsi `data.matrix()`. Khusus untuk prediktor variabel yang disimpan pada `train_x` dan `test_x` lakukan *features scaling* dengan cara membaginya dengan 255.

```{r}
# Predictor variables in `sign_train`
train_x <- 

# Predictor variables in `sign_test`
test_x <- 

# Target variable in `sign_train`
train_y <- 

# Target variable in `sign_test`
test_y <- 
```

___
1. Jika Anda mengecek suatu gambar di dalam data train, kita akan melihat bahwa nilai pixel jatuh dalam rentang 0 sampai 255. Kemudian, apakah tujuan dari membagi nilai pada array tersebut dengan 255?
  - [ ] Menormalisasi nilai yang sebelumnya 0 hingga 255 menjadi -1 hingga 1
  - [ ] Mengubah ukuran lebar (*width*) dan tinggi (*height*) gambar menjadi 1 dimensi, karena data merupakan 3D array (*images*, *width*, *height*)
  - [ ] Menormalisasi rentang nilai yang sebelumnya 0 hingga 255 menjadi 0 hingga 1
  

*Referensi Opsi Bahasa Inggris:*
  - [ ] Normalize the array from 0 to 255 into -1 to 1
  - [ ] Reshape the width and height into single dimension since the data is a 3-d array (images, width, height)
  - [ ] Normalize the array value from 0 to 255 into 0 to 1
  
___


**1.4 Mengubah matriks menjai array**

Selanjutnya, kita harus mengubah matriks prediktor ke dalam bentuk array. Anda dapat menggunakan fungsi `array_reshape(data, dim(data))` untuk mengubah matriks prediktor menjadi array.

```{r}
# Predictor variables in `train_x`
train_x_array <- 

# Predictor variables in `test_x`
test_x_array <- 
```

Kita juga perlu melakukan *one-hot encoding* terhadap target variabel pada data train (`train_y`). Anda dapat menggunakan fungsi `to_categorical()` dari library `Keras`, kemudian simpan sebagai objek `train_y_dummy`.

```{r}
# Target variable in `train_y`
train_y_dummy <- 
```

# 2 Membuat Model Neural Network

Sebelum kita aplikasikan neural network ke dataset `sign-language-mnist`, mari kita periksa pemahaman kita terkait neural network dengan menjawab pertanyaan-pertanyaan di bawah ini:

___
2. Manakah dari pernyataan berikut ini yang **TIDAK BENAR** tentang Neural Network?
  - [ ] Neural network disebut sebagai deep learning jika memiliki lebih dari 1 hidden layer
  - [ ] Neural network dibangun melalui proses meminimalisasi error/loss function
  - [ ] Bobot awal untuk tiap neuron ditentukan secara acak
  - [ ] *Activation function* tidak melakukan transformasi data

*Referensi Opsi Bahasa Inggris:*
  - [ ] The neural network is called deep learning when it has more than one hidden layer
  - [ ] The neural network model is built by minimizing error/loss function
  - [ ] The initial weight  for each neuron is defined randomly
  - [ ] Activation function is not doing any transformation to the data
___

**2.1 Membuat sebuah model dasar menggunakan `keras_model_sequential()`**

Untuk mengatur layer, kita harus membuat model dasar, yaitu model sequential. Panggil fungsi `keras_model_sequential()`, dan gunakan operator *pipe* untuk membangun arsitektur model dari model dasar yang ada.

**2.2 Membangun Arsitektur (menentukan layer, neuron, dan fungsi aktivasi)**

Untuk membangun arsitektur tiap layer, kita akan membuat beberapa model dengan mengatur beberapa parameter. 

Pertama, buat model (simpan dalam `model_base`) dengan mendefinisikan parameter-parameter di bawah ini:
- layer pertama berisi 64 nodes, fungsi aktivasi relu, 784 input shape
- layer kedua berisi 32 nodes, fungsi aktivasi relu
- layer ketiga berisi 24 nodes, fungsi aktivasi softmax

Sebelum membangun arsitekturnya, kita harus mengatur dahulu randomness bobot yang akan digunakan pada epoch pertama menggunakan `set_random_seed()` dari tensorflow. Pastikan kode pada chunk di bawah ini dijalankan secara bersamaan.

```{r}
# your code here
tensorflow::set_random_seed(8)
model_base <- 
```

Kedua, buatlah sebuah model (simpan ke dalam `model_bigger`) dengan mendefinisikan parameter di bawah ini:
- layer pertama berisi 256 node, fungsi aktivasi relu, 784 input shape
- layer kedua berisi 128 node, fungsi aktivasi relu
- layer ketiga berisi 64 node, fungsi aktivasi relu
- layer keempat berisi 24 node, fungsi aktivasi softmax

```{r}
# your code here
tensorflow::set_random_seed(8)
model_bigger <- 
```

Silahkan jawab pertanyaan di bawah ini.
___
3. Dalam membangun arsitektur model neural network, kita mengatur beberapa parameter. Di bawah ini merupakan pertimbangan menggunakan angka-angka tersebut, **KECUALI**? 
  - [ ] Pada layer pertama, digunakan input shape 784 sesuai jumlah prediktor 
  - [ ] Pada output layer, digunakan angka 24 yang merupakan jumlah kategori data
  - [ ] Pada hidden dan output layer, digunakan sembarang angka genap
  
*Referensi Opsi Bahasa Inggris:*
  - [ ] In the first layer, we use 784 input shape based on the number of our predictors
  - [ ] In the output layer, we use 24 that is the number of our categories 
  - [ ] In the hidden and output layer, we use any even number
  
___

**2.3 Membangun arsitektur (menentukan *cost function* dan *optimizer*)**

Kita masih perlu melakukan beberapa pengaturan sebelum melatih `model_base` dan` model_bigger`. Kita harus menyusun model dengan menentukan *loss function*, jenis *optimizer*, dan metrik evaluasi. Anda dapat melakukan *compile* model terhadap `model_base` dan `model_bigger` dengan menggunakan parameter berikut:
- *categorical_crossentropy* sebagai loss function
- *optimizer_adam* sebagai optimizer dengan learning rate *0.001*
- gunakan *accuracy* sebagai metrik evaluasi

```{r}
# your code here

```

```{r}
# your code here

```

**2.4 *Fitting model* di data train (mengatur epoch dan ukuran batch)**

Pada tahap ini, kita fit model menggunakan `epoch = 10`, `batch_size = 150`, dan menambahkan parameter `shuffle = F` agar sampel pada tiap batch tidak diambil secara *random* melainkan terurut (*sequence*) untuk `model_base` dan `model_bigger`. Silahkan simpan hasil fit model ke dalam `history_base` dan `history_bigger`.

```{r}
# your code here
history_base <- 
```

```{r}
# your code here
history_bigger <- 
```

___
4. Dalam fitting model di atas, apa arti dari `epoch = 10`?
  - [ ] Model melakukan proses feed-forward - back propagation untuk seluruh batch sebanyak 10 kali
  - [ ] Model melakukan proses feed-forward - back propagation untuk 10 batch sebanyak 1 kali
  - [ ] Model membagi 1 batch menjadi 10 kelompok training data

*Referensi Opsi Bahasa Inggris:*
  - [ ] The model does the feed-forward - back-propagation for all batch 10 times
  - [ ] The model does the feed-forward - back-propagation for 10 batch 1 times
  - [ ] The model divides one batch into 10 groups of training data
___

# 3 Prediksi ke data test

Untuk mengevaluasi performa model terhadap data yang belum dilihat, kita akan memprediksi data test (`test_x_array`) menggunakan model yang sudah dilatih. Silahkan prediksi menggunakan fungsi `predict()` dan simpan sebagai `pred_base` dan `pred_bigger`.

```{r}
# your code here
pred_base <- predict(object = ..., x = ...)  %>% k_argmax() %>% as.array() %>% as.factor()

pred_bigger <- 
```

# 4 Evaluasi model neural network

**4.1 Confusion Matrix (klasifikasi)**

Anda dapat mengevaluasi model menggunakan beberapa *metrics*. Pada kuis ini, periksalah akurasi dengan membuat confusion matrix. Silahkan gunakan fungsi `confusionMatrix()` dari package `caret`.

Note: jangan lupa untuk melakukan *explicit coercion* `as.factor` bila data Anda belum dalam bentuk faktor.

```{r}
# your code here

```

___  
5. Dari dua confusion matrix di atas, pernyataan di bawah yang paling sesuai adalah?
  - [ ] Jumlah hidden layer dan neuron tidak mempengaruhi performa model
  - [ ] Semakin sedikit hidden layer dan neuron, performa model dapat meningkat karena semakin sedikit features tidak penting yang diekstraksi dari data
  - [ ] Semakin banyak hidden layer dan neuron, performa model dapat meningkat karena semakin banyak features yang dapat diekstraksi dari data
  

*Referensi Opsi Bahasa Inggris:*
  - [ ] The number of hidden layer and neuron does not relate with the model performance
  - [ ] The less hidden layer and neuron, the model may have better performance because less unnecessary features will be extracted from the data
  - [ ] The more hidden layer and neuron, the model may have better performance because more features will be extracted from the data
  
___
  
**4.2 Model Tuning**

Karena kedua model belum memberikan performa yang cukup baik (*best fit*) dimana `model_base` cenderung *underfitting* dan `model_bigger` cenderung *overfitting*, maka akan dilakukan perbaikan pada `model_bigger`. Sekarang, mari kita coba membangun `model_tuning` dengan mengatur parameter sebagai berikut:
- layer pertama berisi 128 nodes, fungsi aktivasi relu, 784 input shape
- layer kedua berisi 64 nodes, fungsi aktivasi relu
- layer ketiga berisi 24 nodes, fungsi aktivasi softmax

```{r}
# your code here
tensorflow::set_random_seed(8)
model_tuning <- 
```

Kemudian, lakukan *compile* model dengan menggunakan parameter berikut:
- *categorical_crossentropy* sebagai loss function
- *optimizer_adam* sebagai optimizer dengan learning rate *0.001*
- gunakan *accuracy* sebagai metrik evaluasi

```{r}
# your code here

```

Terakhir, fit model menggunakan `epoch = 10`, `batch_size = 150`, dan menambahkan parameter `shuffle = F` agar sampel pada tiap batch tidak diambil secara *random* melainkan terurut (*sequence*)

```{r}
# your code here
history_tuning <- 
```

Setelah tuning model, silahkan prediksi `test_x_array` menggunakan `model_tuning`. Silahkan prediksi menggunakan fungsi `predict()` dan simpan sebagai `pred_tuning`

```{r}
# your code here
pred_tuning <- 
```

Evaluasi performa model menggunakan menggunakan metrik akurasi. Silahkan gunakan fungsi `confusionMatrix()` dari package `caret`.

Note: jangan lupa untuk melakukan *explicit coercion* `as.factor` bila data Anda belum dalam bentuk faktor.

```{r}
# your code here

```

Silahkan jawab pertanyaan di bawah ini.
___
6. Hidden layer merupakan tempat dimana informasi dari data diekstraksi. Apa yang dapat Anda simpulkan dari `model_bigger` dan `model_tuning` mengenai hidden layer?
  - [ ] Semakin banyak jumlah hidden layer yang digunakan (*deep*), model neural network cenderung mengalami *underfitting*
  - [ ] Semakin banyak jumlah hidden layer yang digunakan (*deep*), model neural network cenderung mengalami *overfitting*
  - [ ] Menggunakan jumlah hidden layer yang relatif sedikit maupun banyak tidak mempengaruhi performa model

*Referensi Opsi Bahasa Inggris:*
  - [ ] The more number of hidden layers used (*deep*), the neural network model tends to be *underfitting*
  - [ ] The more number of hidden layers used (*deep*), the neural network model tends to be *overfitting*
  - [ ] Using both of small or large number of hidden layers does not influence the model's performance

*Note: Perhatikan kriteria berikut untuk studi kasus ini*
- Model dianggap cukup baik bila akurasi mencapai >= 70% 
- Model dianggap kurang baik bila akurasi di bawah 70%
- Performa model dianggap seimbang di data train maupun data test bila selisih akurasi <= 20%   

___

___
7. Dari 3 model yang telah dibuat (`model_base`, `model_bigger` dan `model_tuning`), model mana yang paling baik untuk kita pilih?
  - [ ] *model_base*, karena akurasinya cukup tinggi dan selisih akurasi antara data train dan data test paling kecil
  - [ ] *model_bigger*, karena akurasinya cukup tinggi dan selisih akurasi antara data train dan data test paling kecil
  - [ ] *model_tuning*, karena akurasinya cukup tinggi dan selisih akurasi antara data train dan data test paling kecil
  

*Referensi Opsi Bahasa Inggris:*
  - [ ] *model_base*, because the accuracy is quite high and the difference in accuracy between train data and test data is the smallest
  - [ ] *model_bigger*, because the accuracy is quite high and the difference in accuracy between train data and test data is the smallest
  - [ ] *model_tuning*, because the accuracy is quite high and the difference in accuracy between train data and test data is the smallest

*Note: untuk studi kasus ini, kita menganggap model yang memiliki akurasi cukup tinggi adalah model  yang memperoleh akurasi di atas 65% baik pada data train maupun pada data test*  
___

Anda telah menyelesaikan pembuatan model deep learning untuk mengklasifikasikan gambar bahasa isyarat. Model ini akan sangat membantu dalam menfasilitasi teman-teman dengan kebutuhan khusus yang berkomunikasi menggunakan bahasa isyarat, agar dapat berkomunikasi dengan masyarat secara umum. Proyek ini dapat dikembangkan lebih jauh lagi menjadi aplikasi komunikasi berbasis bahasa isyarat.

# 5 Pemahaman Metode

Model deep learning sering digunakan pada pengolahan data tidak terstruktur (non-tabular) yang banyak dijumpai saat ini. Beberapa contoh data tidak terstruktur seperti data foto/video dari sosial media, rekaman CCTV, transmisi suara/audio, rangkaian teks atau dokumen, rekaman chat, dll. Struktur data yang tidak beraturan sulit dimodelkan bila menggunakan pemodelan statistik karena sulitnya dalam menentukan feature/informasi yang dibutuhkan. Oleh karena itu, pengolahannya sering menggunakan model deep learning yang mampu melakukan pemilihan fitur dan pembuatan model yang lebih mudah, serta memberikan hasil yang akurat.

Meskipun data tabular juga dapat diselesaikan menggunakan model deep learning, terkadang penggunaan model lain seperti Random Forest atau Decision Tree sudah cukup memadai. Penentuan model *machine learning* yang dipakai memang sangat bergantung pada kasus dan data yang akan diolah.

8. Dibawah ini, manakah dari pasangan kasus dan data yang **harus** dianalisis menggunakan model deep learning?
  - [ ] Prediksi harga rumah; data yang tersedia meliputi data lokasi, jumlah lantai, jumlah kamar, dll. untuk tiap rumah.
  - [ ] Prediksi permintaan jaringan internet; data yang tersedia berupa jumlah permintaan jaringan internet yang direkam secara periodik setiap 1 jam sekali
  - [ ] Pembuatan *speech recognizer*; data yang tersedia berupa set file suara yang direkam oleh orang-orang
  - [ ] Prediksi status kanker; data yang tersedia berupa kolom-kolom karakteristik sel (radius, diameter, bentuk, dll.) yang diambil dari gambar sel pasien kanker/non-kanker 

*Referensi Opsi Bahasa Inggris:*
  - [ ] House price prediction; available data includes location, total floors, number of rooms, etc., for each house
  - [ ] Internet demand prediction; available data includes internet demand data recorded periodically every 1 hour
  - [ ] Creating a speech recognizer; available data includes sound files recorded by people
  - [ ] Cancer diagnosis; available data includes a set of features describing cell characteristics (radius, diameter, shape, etc.) that were extracted from cancer/non-cancer cell images.



